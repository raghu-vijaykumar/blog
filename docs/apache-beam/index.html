<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Apache Beam - Dataflow | Raghu Vijaykumar</title>
<meta name=keywords content="apache beam,dataflow,serverless"><meta name=description content='For Updates Apache Beam Blog and Release Beam Learning Resources Java Examples Beam Katas Learnings Quick Python Snippets/Examples Apache Beam Apache Beam = Batch + Stream
Installing Beam SDK For Release info and blog articles on apache beam follow: https://beam.apache.org/blog/
For Java
implementation "org.apache.beam:beam-sdks-java-core:2.31.0" /* Apache beam for GCP Dataflow */ implementation "org.apache.beam:beam-runners-google-cloud-dataflow-java:2.31.0" implementation "org.apache.beam:beam-sdks-java-io-google-cloud-platform:2.31.0" implementation &#39;org.apache.beam:beam-sdks-java-extensions-google-cloud-platform-core:2.31.0&#39; /* Apache beam for Direct Runner */ implementation "org.apache.beam:beam-runners-direct-java:2.31.0" For Python
pip install &#39;apache-beam[gcp,aws,spark,test,docs]>=2.'><meta name=author content="Me"><link rel=canonical href=https://raghu-vijaykumar.github.io/blog/docs/apache-beam/><link crossorigin=anonymous href=/blog/assets/css/stylesheet.822fdf31f1a1d84e83043e3faecf43e6dbfa4ac397aa562252d0d5418304799a.css integrity="sha256-gi/fMfGh2E6DBD4/rs9D5tv6SsOXqlYiUtDVQYMEeZo=" rel="preload stylesheet" as=style><link rel=icon href=https://raghu-vijaykumar.github.io/blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://raghu-vijaykumar.github.io/blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://raghu-vijaykumar.github.io/blog/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://raghu-vijaykumar.github.io/blog/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://raghu-vijaykumar.github.io/blog/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://raghu-vijaykumar.github.io/blog/docs/apache-beam/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Apache Beam - Dataflow"><meta property="og:description" content='For Updates Apache Beam Blog and Release Beam Learning Resources Java Examples Beam Katas Learnings Quick Python Snippets/Examples Apache Beam Apache Beam = Batch + Stream
Installing Beam SDK For Release info and blog articles on apache beam follow: https://beam.apache.org/blog/
For Java
implementation "org.apache.beam:beam-sdks-java-core:2.31.0" /* Apache beam for GCP Dataflow */ implementation "org.apache.beam:beam-runners-google-cloud-dataflow-java:2.31.0" implementation "org.apache.beam:beam-sdks-java-io-google-cloud-platform:2.31.0" implementation &#39;org.apache.beam:beam-sdks-java-extensions-google-cloud-platform-core:2.31.0&#39; /* Apache beam for Direct Runner */ implementation "org.apache.beam:beam-runners-direct-java:2.31.0" For Python
pip install &#39;apache-beam[gcp,aws,spark,test,docs]>=2.'><meta property="og:type" content="article"><meta property="og:url" content="https://raghu-vijaykumar.github.io/blog/docs/apache-beam/"><meta property="og:image" content="https://raghu-vijaykumar.github.io/blog/beam_logo.jpeg"><meta property="article:section" content="docs"><meta property="og:site_name" content="Raghu Vijaykumar"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://raghu-vijaykumar.github.io/blog/beam_logo.jpeg"><meta name=twitter:title content="Apache Beam - Dataflow"><meta name=twitter:description content='For Updates Apache Beam Blog and Release Beam Learning Resources Java Examples Beam Katas Learnings Quick Python Snippets/Examples Apache Beam Apache Beam = Batch + Stream
Installing Beam SDK For Release info and blog articles on apache beam follow: https://beam.apache.org/blog/
For Java
implementation "org.apache.beam:beam-sdks-java-core:2.31.0" /* Apache beam for GCP Dataflow */ implementation "org.apache.beam:beam-runners-google-cloud-dataflow-java:2.31.0" implementation "org.apache.beam:beam-sdks-java-io-google-cloud-platform:2.31.0" implementation &#39;org.apache.beam:beam-sdks-java-extensions-google-cloud-platform-core:2.31.0&#39; /* Apache beam for Direct Runner */ implementation "org.apache.beam:beam-runners-direct-java:2.31.0" For Python
pip install &#39;apache-beam[gcp,aws,spark,test,docs]>=2.'><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Docs","item":"https://raghu-vijaykumar.github.io/blog/docs/"},{"@type":"ListItem","position":2,"name":"Apache Beam - Dataflow","item":"https://raghu-vijaykumar.github.io/blog/docs/apache-beam/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Beam - Dataflow","name":"Apache Beam - Dataflow","description":"For Updates Apache Beam Blog and Release Beam Learning Resources Java Examples Beam Katas Learnings Quick Python Snippets/Examples Apache Beam Apache Beam = Batch + Stream\nInstalling Beam SDK For Release info and blog articles on apache beam follow: https://beam.apache.org/blog/\nFor Java\nimplementation \u0026#34;org.apache.beam:beam-sdks-java-core:2.31.0\u0026#34; /* Apache beam for GCP Dataflow */ implementation \u0026#34;org.apache.beam:beam-runners-google-cloud-dataflow-java:2.31.0\u0026#34; implementation \u0026#34;org.apache.beam:beam-sdks-java-io-google-cloud-platform:2.31.0\u0026#34; implementation \u0026#39;org.apache.beam:beam-sdks-java-extensions-google-cloud-platform-core:2.31.0\u0026#39; /* Apache beam for Direct Runner */ implementation \u0026#34;org.apache.beam:beam-runners-direct-java:2.31.0\u0026#34; For Python\npip install \u0026#39;apache-beam[gcp,aws,spark,test,docs]\u0026gt;=2.","keywords":["apache beam","dataflow","serverless"],"articleBody":" For Updates Apache Beam Blog and Release Beam Learning Resources Java Examples Beam Katas Learnings Quick Python Snippets/Examples Apache Beam Apache Beam = Batch + Stream\nInstalling Beam SDK For Release info and blog articles on apache beam follow: https://beam.apache.org/blog/\nFor Java\nimplementation \"org.apache.beam:beam-sdks-java-core:2.31.0\" /* Apache beam for GCP Dataflow */ implementation \"org.apache.beam:beam-runners-google-cloud-dataflow-java:2.31.0\" implementation \"org.apache.beam:beam-sdks-java-io-google-cloud-platform:2.31.0\" implementation 'org.apache.beam:beam-sdks-java-extensions-google-cloud-platform-core:2.31.0' /* Apache beam for Direct Runner */ implementation \"org.apache.beam:beam-runners-direct-java:2.31.0\" For Python\npip install 'apache-beam[gcp,aws,spark,test,docs]\u003e=2.31.0' Designing Pipelines What to consider Source: Messages, Database, Files, etc. Data Schema: The structure of the data (preferably lowest granularity). Data is represented as PCollection. Transforms: How to manipulate the data? transform, combine, filter, etc. Transforms on data is called PTransforms. Sink: Where to store the data? S3, BigQuery, etc. Runner: The execution environment. (Look into compatibility matrix) Beam Model Pipeline A pipeline is a graph of transformations that a user constructs that defines the data processing they want to do.\nPCollection Data being processed in a pipeline is part of a PCollection. Types of PCollections based on data source are:\nBounded: it is finite and you know it, as in batch use cases Unbounded: it may be never end, you don’t know, as in streaming use cases Characteristics of PCollection:\nImmutable: State cannot change after it is constructed. Serializable: State of an object can be serialized and transferred in distributed ecosystem. PTransforms The operations executed within a pipeline. These are best thought of as operations on PCollections.\nSDK A language-specific library for pipeline authors (we often call them “users” even though we have many kinds of users) to build transforms, construct their pipelines and submit them to a runner\nRunner You are going to write a piece of software called a runner that takes a Beam pipeline and executes it using the capabilities of your data processing engine.\n:exclamation: Note: Apache beam supports multiple backend like Dataflow, Spark, Flink, etc. Apache Beam feature compatibility matrix :exclamation:\nTransforms Transforms are what change your data.\n[Final Output PCollection] = [Initial Input PCollection].apply([First Transform]) .apply([Second Transform]) .apply([Third Transform]); Java Transform Catalog Python Transfrom Catalog\nParDo ParDo is a Beam transform for generic parallel processing. The ParDo processing paradigm is similar to the “Map” phase of a Map/Shuffle/Reduce-style algorithm.\nParDo is useful for a variety of common data processing operations, including:\nFiltering a data set. Formatting or type-converting each element in a data set. Extracting parts of each element in a data set. Performing computations on each element in a data set. DoFn Lifecycle class DoFn(beam.DoFn): def setup(self): pass def startBundle(self): pass def process(self, element): pass def finishBundle(self): pass def teardown(self): pass Branching Single PCollection output to multiple PCollections.\nnumbers = p | beam.Create([1, 2, 3, 4, 5]) mult5_results = numbers | beam.Map(lambda num: num * 5) mult10_results = numbers | beam.Map(lambda num: num * 10) mult5_results | \"Log multiply 5\" \u003e\u003e LogElements(prefix=\"Multiplied by 5: \") mult10_results | \"Log multiply 10\" \u003e\u003e LogElements(prefix=\"Multiplied by 10: \") Output:\nMultiplied by 10: 10 Multiplied by 5: 5 Multiplied by 10: 20 Multiplied by 5: 10 Multiplied by 10: 30 Multiplied by 5: 15 Multiplied by 10: 40 Multiplied by 5: 20 Multiplied by 10: 50 Multiplied by 5: 25 GroupByKey p | beam.Create([\"apple\", \"ball\", \"car\", \"bear\", \"cheetah\", \"ant\"]) | beam.Map(lambda word: (word[0], word)) | beam.GroupByKey() | LogElements() Output:\n('a', ['apple', 'ant']) ('b', ['ball', 'bear']) ('c', ['car', 'cheetah']) CoGroupByKey Group By Key for multiple List of Key Value Pairs.\ndef apply_transforms(fruits, countries): def map_to_alphabet_kv(word): return (word[0], word) def cogbk_result_to_wordsalphabet(cgbk_result): (alphabet, words) = cgbk_result return WordsAlphabet(alphabet, words[\"fruits\"], words[\"countries\"][0]) fruits_kv = fruits | \"Fruit to KV\" \u003e\u003e beam.Map(map_to_alphabet_kv) countries_kv = countries | \"Country to KV\" \u003e\u003e beam.Map(map_to_alphabet_kv) return ( {\"fruits\": fruits_kv, \"countries\": countries_kv} | beam.CoGroupByKey() | beam.Map(cogbk_result_to_wordsalphabet) ) with beam.Pipeline() as p: fruits = p | \"Fruits\" \u003e\u003e beam.Create( [\"apple\", \"banana\", \"cherry\", \"apricot\", \"b-fruit\"] ) countries = p | \"Countries\" \u003e\u003e beam.Create([\"australia\", \"brazil\", \"canada\"]) (apply_transforms(fruits, countries) | LogElements()) Output:\nWordsAlphabet(alphabet:'a', fruit='['apple', 'apricot']', country='australia') WordsAlphabet(alphabet:'b', fruit='['banana', 'b-fruit']', country='brazil') WordsAlphabet(alphabet:'c', fruit='['cherry']', country='canada') Partition def partition_fn(number, num_partitions): if number \u003e 100: return 0 else: return 1 with beam.Pipeline() as p: results = ( p | beam.Create([1, 2, 3, 4, 5, 100, 110, 150, 250]) | beam.Partition(partition_fn, 2) ) results[0] | \"Log numbers \u003e 100\" \u003e\u003e LogElements(prefix=\"Number \u003e 100: \") results[1] | \"Log numbers \u003c= 100\" \u003e\u003e LogElements(prefix=\"Number \u003c= 100: \") Output:\nNumber \u003c= 100: 1 Number \u003c= 100: 2 Number \u003c= 100: 3 Number \u003c= 100: 4 Number \u003c= 100: 5 Number \u003c= 100: 100 Number \u003e 100: 110 Number \u003e 100: 150 Number \u003e 100: 250 Aggregation Aggregation - Count\np | beam.Create(range(1, 11)) | beam.combiners.Count.Globally() | LogElements() Output:\n10 Aggregation - Average\np | beam.Create(range(1, 11)) | beam.combiners.Mean.Globally() | LogElements() Output:\n5.5 Combine PLAYER_1 = \"Player 1\" PLAYER_2 = \"Player 2\" PLAYER_3 = \"Player 3\" with beam.Pipeline() as p: ( p | beam.Create( [ (PLAYER_1, 15), (PLAYER_2, 10), (PLAYER_1, 100), (PLAYER_3, 25), (PLAYER_2, 75), ] ) | beam.CombinePerKey(sum) | LogElements() ) Output:\n('Player 1', 115) ('Player 2', 85) ('Player 3', 25) Side Input with beam.Pipeline() as p: cities_to_countries = { \"Beijing\": \"China\", \"London\": \"United Kingdom\", \"San Francisco\": \"United States\", \"Singapore\": \"Singapore\", \"Sydney\": \"Australia\", } persons = [ Person(\"Henry\", \"Singapore\"), Person(\"Jane\", \"San Francisco\"), Person(\"Lee\", \"Beijing\"), Person(\"John\", \"Sydney\"), Person(\"Alfred\", \"London\"), ] ( p | beam.Create(persons) | beam.ParDo(EnrichCountryDoFn(), cities_to_countries) | LogElements() ) Output:\nPerson[Henry,Singapore,Singapore] Person[Jane,San Francisco,United States] Person[Lee,Beijing,China] Person[John,Sydney,Australia] Person[Alfred,London,United Kingdom] Side Output with beam.Pipeline() as p: results = ( p | beam.Create([10, 50, 120, 20, 200, 0]) | beam.ParDo(ProcessNumbersDoFn()).with_outputs( num_above_100_tag, main=num_below_100_tag ) ) results[num_below_100_tag] | \"Log numbers \u003c= 100\" \u003e\u003e LogElements( prefix=\"Number \u003c= 100: \" ) results[num_above_100_tag] | \"Log numbers \u003e 100\" \u003e\u003e LogElements( prefix=\"Number \u003e 100: \" ) Output:\nNumber \u003c= 100: 10 Number \u003c= 100: 50 Number \u003e 100: 120 Number \u003c= 100: 20 Number \u003e 100: 200 Number \u003c= 100: 0 Composite Transforms Adding Multiple transforms, Creating your own transforms.\nclass ExtractAndMultiplyNumbers(beam.PTransform): def expand(self, pcoll): return ( pcoll | beam.FlatMap(lambda line: map(int, line.split(\",\"))) | beam.Map(lambda num: num * 10) ) with beam.Pipeline() as p: ( p | beam.Create([\"1,2,3,4,5\", \"6,7,8,9,10\"]) | ExtractAndMultiplyNumbers() | LogElements() ) Output:\n10 20 30 40 50 60 70 80 90 100 Windowing Windowing is very useful\nBatch Processing: Handling Chunked data. Streaming Processing: Dealing with out of order data. Grouping operations work on windows, for example:\nBounded data source, can wait till it receives all elements (not memory efficient though) GroupByKey, Combine operations from unbounded data is split into windows for processing. (memory efficient) Windowing is performed on timestamps.\nWe can assign our own timestamp to each element. i.e. Processing Time We can use the event time if already present in the element. i.e. Event Time Late arriving data is placed in correct global windows (In order output) :exclamation: Note: Beam’s default windowing behavior is to assign all elements of a PCollection to a single, global window and discard late data, even for unbounded PCollections. Before you use a grouping transform such as GroupByKey on an unbounded PCollection, you must do at least one of the following:\nSet a non-global windowing function. See Setting your PCollection’s windowing function. Set a non-default trigger. This allows the global window to emit results under other conditions, since the default windowing behavior (waiting for all data to arrive) will never occur. :exclamation: Fixed Time Windows Window to divide a PCollection into fixed windows, each 60 seconds in length\nfrom apache_beam import window fixed_windowed_items = ( items | 'window' \u003e\u003e beam.WindowInto(window.FixedWindows(60))) Sliding Time Windows Window to divide a PCollection into sliding time windows. Each window is 30 seconds in length, and a new window begins every five seconds\nfrom apache_beam import window sliding_windowed_items = ( items | 'window' \u003e\u003e beam.WindowInto(window.SlidingWindows(30, 5))) Session Windows Window to divide a PCollection into session windows, where each session must be separated by a time gap of at least 10 minutes (600 seconds), These are data dependent windows.\nfrom apache_beam import window session_windowed_items = ( items | 'window' \u003e\u003e beam.WindowInto(window.Sessions(10 * 60))) Single Global Window If your PCollection is bounded (the size is fixed), you can assign all the elements to a single global window. The following example code shows how to set a single global window for a PCollection\nfrom apache_beam import window global_windowed_items = ( items | 'window' \u003e\u003e beam.WindowInto(window.GlobalWindows())) Data Freshness and System latency Data freshness is the amount of time between the real time and the output watermark (oldest unprocessed element).\nSystem latency is the current maximum duration that an item of data has been processing or awaiting processing.\nData flow Autoscaling Metric Stable Data freshness Ever Increasing data freshness Stable System Latency Good Pace (Relax) Data Accumulation (High Backlog Autoscale) Ever increasing system latency Complex Processing, (High CPU Usage Autoscale) Complex Processing and Data Accumulation (High Backlog \u0026 High CPU Autoscale) Watermarks Watermark is a timestamp that is used to determine the close of a window.\nWindow = [Start Time, End Time] Watermark = [Start Time, End Time + Max Allowed Lag time]\nJust in Time: Within the watermark. Late Data: Outside the watermark.\nIdeal Window Processing Latency in data Latency in data may occur due to various reasons:\nLate arrival - network latency Different data processing times.etc… Lag Time: Its is defined as the difference in time it is expected to arrive and when it actually arrives.\nManaging Late Data A windowing strategy that will allow late data up to two days after the end of a window.\npc | beam.WindowInto( FixedWindows(60), trigger=trigger_fn, accumulation_mode=accumulation_mode, timestamp_combiner=timestamp_combiner, allowed_lateness=Duration(seconds=2*24*60*60)) # 2 days Adding timestamps to raw data class AddTimestampDoFn(beam.DoFn): def process(self, element): # Extract the numeric Unix seconds-since-epoch timestamp to be # associated with the current log entry. unix_timestamp = extract_timestamp_from_log_entry(element) # Wrap and emit the current entry and new timestamp in a # TimestampedValue. yield beam.window.TimestampedValue(element, unix_timestamp) timestamped_items = items | 'timestamp' \u003e\u003e beam.ParDo(AddTimestampDoFn()) Triggers Triggers determine when to emit aggregated results(pane) from a window.\nEvent Time Triggers Operate on event time.\nProcessing Time Triggers Operate on processing time.\nData Driven Triggers Operates by examining the data arrives and firing when it meets a certain condition.\nComposite Triggers Combination of multiple triggers. Composite trigger that fires whenever the pane has at least 100 elements, or after a minute.\npcollection | WindowInto( FixedWindows(1 * 60), trigger=Repeatedly( AfterAny(AfterCount(100), AfterProcessingTime(1 * 60))), accumulation_mode=AccumulationMode.DISCARDING) Window Accumulation Modes Accumulated triggered data and resend or drop already triggered data.\nAccumulation Mode pcollection | WindowInto( # Sliding windows of 1 minute, every 5 seconds SlidingWindows(60, 5), # Relative to watermark, trigger: trigger=AfterWatermark( early=AfterProcessingTime(delay=30), # -- fires 30 seconds after pipeline start late=AfterCount(1)), # -- fires when at least one element is late accumulation_mode=AccumulationMode.ACCUMULATING) # the pane should have all elements Discarding Mode pcollection | WindowInto( # Fixed windows of 60 seconds FixedWindows(60), trigger=Repeatedly( AfterAny(AfterCount(100), AfterProcessingTime(1 * 60))), # -- fires after 100 elements or 1 minute accumulation_mode=AccumulationMode.DISCARDING) # trigger on new records allowed_lateness=Duration(seconds=2*24*60*60)) # 2 days Sources and Sinks (IO) Source: Input data Sink: Output data\nBounded Sources (Batch): BigQuery, Cloud Storage, Cloud Spanner\nSplit work into smaller chunks, known as bundles. Provide estimate of progress. Track if units of work can be broken into smaller bundles (Dynamic work rebalancing). Unbounded Sources (Stream): Pub/Sub\nCheckpointing not to read same data. Provide data to service on what point the data is complete using watermarks. Deduping data using record/message ID. List of Beam IO Developing Custom IO\nText IO # Read from text ( p | beam.io.ReadFromText(file_path) | beam.Map(lambda country: country.upper()) | LogElements() ) # File io reading with file names with beam.Pipeline() as p: read_pipeline = ( p | fileio.MatchFiles(file_pattern) # match file patter like hdfs://path/to/*.txt | fileio.ReadMatches() # read file | beam.Reshuffle() # shuffle data file_and_metadata = ( read_pipeline | beam.Map(lambda x: (x.metadata.path, x.read_utf8())) # Access file metadata # FileIO processing files as they arrive p.apply( FileIO.match() .file_pattern(file_pattern) .continuously( # continuously read files Duration.standardSeconds(30), Watch.Growth.afterTimeSinceNewOutput(Duration.standardHours(1)) # Every 30 seconds for 1 hour ) # GCS Buckets have watch functionality to monitor for new files and send a notification to a topic with beam.Pipeline() as p: read_files = ( p | beam.io.ReadFromPubSub(subscription_details) | \u003cdecode file name\u003e files_and_content = ( read_files | ReadAllFromText()) # Write to file csv.apply( \"Write to storage\", TextIO.write().to(file_path).withSuffix(\".csv\") # Writing to dynamic destination my_pcollection | beam.io.fileio.WriteToFiles( path='/my/file/path', destination=lambda record: 'avro' if record['type'] == 'A' else 'csv' sink=lambda destination, AvroSink() if destination == 'avro' else CsvSink(), file_naming=beam.io.fileio.destination_prefix_naming()) BigQueryIO # Read from BigQuery (Using query) max_temparatures = ( p | 'QueryTable' \u003e\u003e beam.io.ReadFromBigQuery(query='SELECT max_temperature FROM clouddataflow-readonly.samples.weather_stations', use_standard_sql=True) # Source using big query | 'ExtractMaxTemp' \u003e\u003e beam.Map(lambda row: (row['max_temperature'])) # Map results ) // Read from BigQuery (Using BigQuery Storage API) pipeline.apply(\"Read from BiqQuery table\", BigQueryIO.readTableRows() .from(String.format(\"%s:%s.%s\", projectId, datasetId, tableId)) .withMethod(BigQueryIO.Read.Method.DIRECT_READ) .withRowRestriction .withSelectedFields(Arrays.asList(\"max_temperature\"))) .apply(\"TableRows to MyData\", MapElements.into(TypeDescriptors.of(MyData.class)) .via(MyData::fromTableRow)); # BigQuery IO Write - Dynamic destination def table_fn(element, fictional_characters): if element in fictional_characters: return 'my_dataset.fictional_quotes' else: return 'my_dataset.real_quotes' quotes | 'WriteWithDynamicDestination' \u003e\u003e beam.io.WriteToBigQuery( table_fn, schema=table_schema, #'quote:STRING,author:STRING,length:INTEGER' table_side_inputs=fictional_characters_view,) PubSub IO # reading from pubsub topic p.apply(\"Read from PubSub\", PubsubIO.ReadStrings().from_topic(topic_name)) .apply(WindowInto(FixedWindows.of(Duration.standardMinutes(window_size)))) Kafka IO // Read from Kafka topics PCollection\u003cKV\u003cString, String\u003e\u003e kafka_messages = pipeline.apply(\"Read from Kafka\", KafkaIO.\u003cString, String\u003eread() .withConsumerConfigUpdates(ImmutableMap.of( ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\" )) .withBootstrapServers(options.get(\"bootstrap.servers\")) // \"localhost:9092\" .withTopics(list_of_topics) // \"my-topic\" .withKeyDeserializerAndCoder(CustomKeyDeserializer.class) .withValueDeserializerAndCoder(CustomValueDeserializer.class)); .withoutMetadata()); Note: KafkaIO is built in java for python it uses cross language transforms.\n# read from a kafka topic pipeline | 'Read from Kafka' \u003e\u003e beam.io.ReadFromKafka( consumer_config={ 'bootstrap.servers': bootstrap_servers, topics: [topic], }, ) BigTable IO // Read from big table with row filter PCollection\u003cBigTableWriteResults\u003e writeResults = p.apply(\"Read from BigTable\", BigtableIO.Read() .withProjectId(project_id) .withInstanceId(instance_id) .withTableId(table_id) .withRowFilter(RowFilter.chain())); // Read with column filter and ByteKeyRange is also available. // BigTable IO Writing with additional actions PCollection\u003cT\u003e moreData = ...; moreData.apply(\"wait for writes\", Wait.on(writeResults)) .apply(\"Do Something\", ParDo.of(customOperation())); Schema A schema describes a type in terms of fields and its values.\nFields can have string names or numeric indices. Field can be one of primitive types (string, int, float, bool, bytes) or a composite type (a list or a map). Fields can be optional, repeated, or nullable. Schemas can be Avro, ProtoBuf, or JSON.\n// Schemas can be inferred at the sources PCollection\u003cPurchase\u003e purchase = p.apply(PubSubIO.readAvros(Purchase.class).from_topic(topic_name)); // With Schema filtering purchases in a geographic region purchase.apply( Filter.whereFieldName(\"location.lat\",(double lat) -\u003e lat \u003e 40.0 \u0026\u0026 lat \u003c 45.0) .whereFieldName(\"location.lon\",(double lon) -\u003e lon \u003e -74.0 \u0026\u0026 lon \u003c -70.0); // Total purchase per transaction PCollection\u003cUserPurchases\u003e userSums = purchase.apply(Join.innerJoin(transactions).using(transactionId)) .apply(Select.fieldNames(\"lhs.userId\", \"rhs.totalPurchase\")) .apply(Group.ByField(\"userId\").aggregate(Sum.ofLongs(), \"totalPurchase\")); State and Timers Stateful Transformations in ParDo\nThe input collection needs to be a PCollection of KV\u003c\u003e. Any Stateful computations are stored in a local persistent mutable state, it is partitioned by key and window. Types of State Variables:\nValue: Read/Write any value (but always the whole value). Bag: Cheap Append no ordering on read. Combining: Associative and Commutative compaction. Map: Read/Write just keys you specify. Set: Membership Checking. Timers ensure the state is cleared in regular intervals. Using\nEvent time Timers Output based on completeness of data Absolute times(at 5 AM) Final/Authoritative output Processing time Timers Timeouts Relative Times (every 5 mins) Periodic output based on state # Stateful Buffering class StatefulBufferingFn(beam.DoFn): MAX_BUFFER_SIZE = 500; BUFFER_STATE = BagStateSpec('buffer', EventCoder()) COUNT_STATE = CombiningValueStateSpec('count', VarIntCoder(), combiners.SumCombineFn()) def process(self, element, buffer_state=beam.DoFn.StateParam(BUFFER_STATE), count_state=beam.DoFn.StateParam(COUNT_STATE)): buffer_state.add(element) count_state.add(1) count = count_state.read() if count \u003e= MAX_BUFFER_SIZE: for event in buffer_state.read(): yield event count_state.clear() buffer_state.clear() # Stateful Buffering with Event Time timer class StatefulBufferingFn(beam.DoFn): EXPIRY_TIMER = TimerSpec('expiry', TimeDomain.WATERMARK) def process(self, element, w=beam.DoFn.WindowParam, buffer_state=beam.DoFn.StateParam(BUFFER_STATE), count_state=beam.DoFn.StateParam(COUNT_STATE), expiry_timer=beam.DoFn.TimerParam(EXPIRY_TIMER)): expiry_timer.set(w.end + ALLOWED_LATENESS) … same logic as above … @on_timer(EXPIRY_TIMER) def expiry(self, buffer_state=beam.DoFn.StateParam(BUFFER_STATE), count_state=beam.DoFn.StateParam(COUNT_STATE)): events = buffer_state.read() for event in events: yield event buffer_state.clear() count_state.clear() # Stateful processing with Processing time timer class StatefulBufferingFn(beam.DoFn): STALE_TIMER = TimerSpec('stale', TimeDomain.REAL_TIME) MAX_BUFFER_DURATION = 1 def process(self, element, w=beam.DoFn.WindowParam, buffer_state=beam.DoFn.StateParam(BUFFER_STATE), count_state=beam.DoFn.StateParam(COUNT_STATE), expiry_timer=beam.DoFn.TimerParam(EXPIRY_TIMER), stale_timer=beam.DoFn.TimerParam(STALE_TIMER)): if count_state.read() == 0: stale_timer.set(time.time() + StatefulBufferingFn.MAX_BUFFER_DURATION) … same logic as above … @on_timer(STALE_TIMER) def stale(self, buffer_state=beam.DoFn.StateParam(BUFFER_STATE), count_state=beam.DoFn.StateParam(COUNT_STATE)): events = buffer_state.read() for event in events: yield event buffer_state.clear() count_state.clear() Use Cases:\nDomain Specific triggering (“output when five people who live in Seattle have check in”) Slowly Changing Dimensions(“Update FX rates for a currency”) Streaming Joins Fine Grained Aggregations Per key workflows Timely Processing\nSplittable DoFn With Spilttable DoFn’s the processing can be split into bundles based on backlog, this unifies batch and stream processing and doesn’t differentiate between bounded and unbounded source.\nThe SourceIO is responsible for providing backlog estimate and watermark checkpoints, the runner can use this information to tune its execution and performance.\nclass FileToWordsRestrictionProvider(beam.transforms.core.RestrictionProvider ): def initial_restriction(self, file_name): return OffsetRange(0, os.stat(file_name).st_size) def create_tracker(self, restriction): return beam.io.restriction_trackers.OffsetRestrictionTracker() def split(self, file_name, restriction): # Compute and output 64 MiB size ranges to process in parallel split_size = 64 * (1 \u003c\u003c 20) i = restriction.start while i \u003c restriction.end - split_size: yield OffsetRange(i, i + split_size) i += split_size yield OffsetRange(i, restriction.end) class FileToWordsFn(beam.DoFn): def process( self, file_name, # Alternatively, we can let FileToWordsFn itself inherit from # RestrictionProvider, implement the required methods and let # tracker=beam.DoFn.RestrictionParam() which will use self as # the provider. tracker=beam.DoFn.RestrictionParam(FileToWordsRestrictionProvider())): with open(file_name) as file_handle: file_handle.seek(tracker.current_restriction.start()) while tracker.try_claim(file_handle.tell()): yield read_next_record(file_handle) # Providing the coder is only necessary if it can not be inferred at # runtime. def restriction_coder(self): return ... Cross Language Transforms Transforms can be shared among SDKs in different languages.\nBest Practices AutoValue generation // use AutoValue Class builder to generate POJO's when not using beam schemas @DefaultSchema(AutoValueSchema.class) @AutoValue public abstract class TransactionValue { public abstract String getBank(); public abstract double getPurchaseAmount(); } Using Schema Use Schemas to define the schema of the PCollection.\nimport typing class Purchase(typing.NamedTuple): user_id: str # The id of the user who made the purchase. item_id: int # The identifier of the item that was purchased. shipping_address: ShippingAddress # The shipping address, a nested type. cost_cents: int # The cost of the item transactions: typing.Sequence[Transaction] # The transactions that paid for this purchase (a list, since the purchase might be spread out over multiple credit cards). Dead Lettering In message queueing the dead letter queue is a service implementation to store messages that meet one or more of the following criteria:\nMessage that is sent to a queue that does not exist. Queue length limit exceeded. Message length limit exceeded. Message is rejected by another queue exchange. Message reaches a threshold read counter number, because it is not consumed. Sometimes this is called a “back out queue”. The message expires due to per-message TTL (time to live) Message is not processed successfully. Dead letter queue storing of these messages allows developers to look for common patterns and potential software problems\nfinal TupleTag\u003cString\u003e deadLetterTag = new TupleTag\u003c\u003e(\"deadLetter\"); final TupleTag\u003cString\u003e successTag = new TupleTag\u003c\u003e(\"success\"); PCollection input =/**/; PCollectionTuple output = input.apply(ParDo.of(new DoFn\u003cString, String\u003e() { @ProcessElement public void processElement(ProcessContext c) { String element = c.element(); try{ c.output(process(c.element())); } catch (Exception e) { c.sideOutput(deadLetterTag, c.element); } } })).writeOutPutTags(successTag, TupleTagList.of(deadLetterTag)); // Write dead letter elements to separate sink (Preferred BigQuery sink) output.get(deadLetterTag).apply(TextIO.write().to(\"/tmp/deadLetter\")); // Process the successful elements output.get(successTag).apply(TextIO.write().to(\"/tmp/success\")); Json Data Handling // AutoValue Schema for Person @DefaultSchema(AutoValueSchema.class) @AutoValue abstract static class Person { public static Person of(String name, Integer height, Boolean knowsJavascript) { return new AutoValue_ToJsonTest_Person(name, height, knowsJavascript); } public abstract String getName(); public abstract Integer getHeight(); public abstract Boolean getKnowsJavascript(); } // Schema for Person Schema personSchema = Schema.builder() .addStringField(\"name\") .addInt32Field(\"height\") .addBooleanField(\"knowsJavascript\") .build(); // Convert Person to Json PCollection\u003cRow\u003e personRows = persons.apply(ToJson.of()).apply(JsonToRow.withSchema(personSchema)); // Convert Json to Person PCollection\u003cPerson\u003e persons = json.apply( JsonToRow.withSchema(personSchema)).apply(Convert.to(Person.class)); // Use dead letter sink for failed messages JsonUtils.java\nUtilize DoFn LifeCycle Use DoFn for micro batching\nclass DoFn(beam.DoFn): def setup(self): pass def startBundle(self): # Start Micro batch operations to external services pass def process(self, element): pass def finishBundle(self): # Finish Micro batch operations to external services pass def teardown(self): pass Performance Considerations/Optimizations Move steps that reduce data up the pipeline to reduce data volume, like filtering. Apply data transforms serially and let Dataflow optimize the DAG, multiple steps can be fused in a single stage for execution in the same worker node. External systems look out for back pressure, ensure system is configured for peak volume Enable autoscaling to downscale if workers are underutilized. Use Efficient Coders, i.e, when only part of the data needs to be deserialized for the pipeline and other information can be masked, use such coder’s like AvroCoders and ProtoCoders. Use Window + Combine using keys when dealing with large windowed aggregations. Use Reshuffling and SideInputs to next steps in dataflow during Fan out operations (One element generates multiple elements), These reshuffling work re-balancing to kick in without any fusion operation which may act as a bottleneck on executing that in a single worker. Use less logging, and dead letter patterns for error logging with count. i.e, Request to /api/service failed 10 times, rather than writing the log 10 times. Data Skew in keys may cause high load on few workers, like null key may have 500elements/sec and other keys may be significantly less. Use enableHotKeyLogging to detect these keys and try using fan outs and reshuffling. Key Space and Parallelism Low Parallelism (Too Few Keys) - Use Window + Key High Parallelism (Too Many keys) - use hashing and decrease keys Don’t use compressed text files as a source this clogs source Only one machine can read compressed file. Fused stages will need to run on the same worker. A single machine will need to push data from the file to all other machines. Collocation of other services helps in performance (Same region/zone) Use Dataflow Shuffle/FlexRs for Batch and Use Streaming Engine for Streaming pipelines. Dataflow Patterns - 1 Dataflow Patterns - 2 Beam pipeline patterns\nBeam SQL Beam SQL allows a Beam user (currently only available in Beam Java and Python) to query bounded and unbounded PCollections with SQL statements.\nFeatures:\nWorks on stream and batch inputs. Can be embedded in an existing pipeline using SqlTransform, which can be mixed with PTransforms. Supports User defined functions. Supports multiple dialects Beam Calcite SQL (OSS SQL dialect Compatibility) Google ZetaSQL (BigQuery compatible) Integrated with Schema. Stream aggregation supports windowing. Components Name Description BigQuery UI Analytical Queries over historical data Dataflow SQL UI Analytical Queries over real-time data Beam SQL Integrating SQL within Beam Pipelines // Updating SQL statements in existing Beam SQL pipeline String sql = \"SELECT MY_FUNC(c1), c2 FROM PCOLLECTION\"; PColl\u003cRow\u003e result = pipeline.apply(SqlTransform.query(sql) .addUdf(MY_FUNC, MyFunc.class)); // Dataflow SQL Template Pipeline pipeline = Pipeline.create(); DataCatalogTableProvider tableProvider = DataCatalogTableProvider.create(options); SqlTransform sqlTransform = p.apply(SqlTransform.query(options.getQueryString()).withDefaultTableProvider(tableProvider)); for(Output output : options.getOutputs()) { sqlTransform.apply(createSink(output, tableProvider)); } pipeline.run(); Dataflow SQL Features:\nBeam ZetaSQL SqlTransform in Dataflow flex template Acts as an optional engine for long running batch jobs. Syntax:\n# We can specify other dataflow pipeline options also gcloud dataflow sql query \\ --job-name=JOB_NAME \\ --region=REGION \\ --bigquery-table=BIGQUERY_TABLE \\ --bigquery-dataset=BIGQUERY_DATASET \\ --bigquery-project=BIGQUERY_PROJECT \\ --parameter=NAME:TYPE:VALUE \\ 'SQL_QUERY' # Sample Queries with parameters gcloud dataflow sql query \\ --job-name=job-name \\ --region=region \\ --bigquery-dataset=destination-dataset \\ --bigquery-table=destination-table \\ --parameter=status:STRING:dropoff \\ --parameter=price_min:FLOAT64:5.5 \\ 'SELECT * FROM pubsub.topic.`pubsub-public-data`.`taxirides-realtime` WHERE ride_status = @status AND meter_reading \u003e= @price_min' # With Arrays gcloud dataflow sql query \\ --job-name=job-name --region=region --bigquery-dataset=destination-dataset \\ --bigquery-table=destination-table \\ --parameter='status:ARRAY:[\"pickup\", \"enroute\", \"dropoff\"]' \\ 'SELECT * FROM pubsub.topic.`pubsub-public-data`.`taxirides-realtime` WHERE ride_status IN UNNEST(@status)' # With Structs gcloud dataflow sql query \\ --job-name=job-name \\ --region=region \\ --bigquery-dataset=destination-dataset \\ --bigquery-table=destination-table \\ --parameter='date_min:STRING:2020-01-01 00:00:00.000 UTC' \\ 'SELECT * FROM pubsub.topic.`pubsub-public-data`.`taxirides-realtime` WHERE event_timestamp \u003e= TIMESTAMP (@date_min)' Creating external Table\nData Sources and Destinations\nWindowing -- Fixed Windows SELECT productid, Tumble_start(timestamp, INTERVAL 10 second) AS window_start, Count(transactionid) AS num_purchases FROM pubsub.topic.`instant-insights`.`retaildemo-online-purchase-json` AS pr GROUP BY productid, Tumble(timestamp, INTERVAL 10 second); -- Sliding/Hopping windows SELECT productid, Hop_start(timestamp, INTERVAL 10 second, INTERVAL 20 second) AS window_start, Hop_end(timestamp, INTERVAL 10 second, INTERVAL 20 second) AS window_end, Count(transactionid) AS num_purchases FROM pubsub.topic.`instant-insights`.`retaildemo-online-purchase-json` AS pr GROUP BY productid, Hop(timestamp, INTERVAL 10 second, INTERVAL 20 second); -- Session Windows SELECT userid, Session_start(timestamp, INTERVAL 10 minute) AS window_start, Session_end(timestamp, INTERVAL 10 minute) AS window_end, Count(transactionid) AS num_transactions FROM pubsub.topic.`instant-insights`.`retaildemo-online-purchase-json` AS pr GROUP BY userid, Session(timestamp, INTERVAL 10 minute); Beam DataFrames Beam Notebooks Dataflow Developing and Testing Pipelines Developing Pipelines Testing Pipelines (CI/CD) Unit Testing Integration Testing End To End Testing Pipeline Options Deploying Pipelines Dataflow Snapshots Updating pipelines Dataflow Flex Templates Google provides and list of Steaming, Batch and other utility templates, Flex templates are a way of creating your custom pipeline and building a template using it for reusability.\nNetwork and Security Data locality Regional endpoints\nFeatures:\nBackend that deploys and controls Dataflow workers (Available in only few regions). Information flow -\u003e Health Checks, Work Items, Autoscaling, Self healing, Failures, Job Metadata. Use cases:\nSecurity and Compliance needs (Data should not leave the country). Minimize network latency and transport costs Use Pipeline Options to specify –region and –zone endpoints.\nConfigure Networking Shared VPC Dataflow can use its own network or a subnet from host project. Number of VM’s is constrained by IP block size. /29 subnet - max workers is 4. Dataflow requires Compute Network User role. Configurable by using –network and –subnet pipeline options(use one). IP Use private IP’s to secure data processing infrastructure. Block internet access. Access control is limited to Same VPC Network Other VPC Networks - VPC Peering. Pipeline options Python: –no_use_public_ips Java: usePublicIps=false. Encryption Understanding datastore associated with Dataflow:\nPersistent Disks Storage Buckets Dataflow Shuffle Backend - Batch Jobs Streaming Engine Backend - Streaming Jobs Encryption:\nGoogle Managed Encryption Key - Job metadata Customer Managed Encryption Key - Data keys stored in grouping operations use encryption Cloud KMS CryptoKey Encrypter/Decrypter Role is required for Dataflow Service account.\nPipeline options\nPython: --dataflow_kms_key=projects/$PROJECT/locations/$REGION/keyRings/$KEY_RING/cryptoKeys/$Key Java: --dataflowKmsKey=projects/$PROJECT/locations/$REGION/keyRings/$KEY_RING/cryptoKeys/$Key Note: Only regional keys are supported, No Global keys.\nReliability Batch Pipelines\nRerun the job if it fails Source data is not lost, and partial data written to sinks can be re-written Stream Pipelines\nProtection against failure modes User Code Failure Transient Errors Data Corruption Service Failure Zonal Failure Regional Failure Handling Failures A Batch pipeline get retried up to 4 times, until its marked ad failed. A Streaming pipeline can stall indefinitely, Handle Failures using Monitoring pipeline metrics, data freshness, error log count, set up alerting polices. Implement Dead Letter Sinks. Dataflow is a regional service, avoid specifying zones, as it can avoid zonal outages. (Only on job start, a region or zone is immutable after job start) Isolate data processing to one region or use multi regional source (US) and sinks(US) (Data will be synced later if there is any regional outage). Using a source(US-Central) in one region and sink(Us-West) in another have multiple point of failures due to cross regional dependency. Use Pubsub Snapshots as a disaster recovery strategy to avoid data loss. Reconciliation of data written in sinks Message Reprocessing Disrupts exactly once processing Use Dataflow Snapshots Restart a pipeline without reprocessing in-flight data No data loss with minimum downtimes. Options to create snapshot with pubsub source. Snapshots are regional, we should wait for a region to come back online to restart processing. Use High availability configurations considering downtime, data loss and cost. Dataflow Shuffle Service: Batch Features:\nFaster Execution Time of batch pipeline. Reduced consumption on worker’s CPU, memory and storage. Better autoscaling Better Fault tolerance Flexible Resource Scheduling (FlexRS) Features:\nReduce batch processing costs because of Advanced Scheduling. Dataflow Shuffle service. Mix of preemptive and Standard VMs. Execution within 6 hours of job creation Suitable for non time-critical workloads. Early validation run at job submission. Dataflow Streaming Service Features:\nReduced consumption of worker CPU, memory and storage. Lower resource and quota consumption. More responsive to autoscaling Improved supportability Monitoring and Debugging Pipelines Further Reading Beam Programming Guide Streaming 101 World beyond batch Streaming 102 World beyond batch Understanding Watermarks Cloud Dataflow How To ","wordCount":"4527","inLanguage":"en","image":"https://raghu-vijaykumar.github.io/blog/beam_logo.jpeg","datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://raghu-vijaykumar.github.io/blog/docs/apache-beam/"},"publisher":{"@type":"Organization","name":"Raghu Vijaykumar","logo":{"@type":"ImageObject","url":"https://raghu-vijaykumar.github.io/blog/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://raghu-vijaykumar.github.io/blog/ accesskey=h title="Raghu Vijaykumar (Alt + H)"><img src=https://raghu-vijaykumar.github.io/apple-touch-icon.png alt aria-label=logo height=35>Raghu Vijaykumar</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://raghu-vijaykumar.github.io/blog/about/ title=about><span>about</span></a></li><li><a href=https://raghu-vijaykumar.github.io/blog/docs/ title=docs><span>docs</span></a></li><li><a href=https://raghu-vijaykumar.github.io/blog/posts/ title=posts><span>posts</span></a></li><li><a href=https://raghu-vijaykumar.github.io/blog/tags/ title=tags><span>tags</span></a></li><li><a href=https://github.com/raghu-vijaykumar title=Github><span>Github</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://raghu-vijaykumar.github.io/blog/>Home</a>&nbsp;»&nbsp;<a href=https://raghu-vijaykumar.github.io/blog/docs/>Docs</a></div><h1 class="post-title entry-hint-parent">Apache Beam - Dataflow</h1><div class=post-meta>22 min&nbsp;·&nbsp;4527 words&nbsp;·&nbsp;Me</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#for-updates>For Updates</a></li></ul><ul><li><a href=#what-to-consider>What to consider</a></li><li><a href=#beam-model>Beam Model</a><ul><li><a href=#pipeline>Pipeline</a></li><li><a href=#pcollection>PCollection</a></li><li><a href=#ptransforms>PTransforms</a></li><li><a href=#sdk>SDK</a></li><li><a href=#runner>Runner</a></li></ul></li><li><a href=#transforms>Transforms</a><ul><li><a href=#pardo>ParDo</a></li><li><a href=#branching>Branching</a></li><li><a href=#groupbykey>GroupByKey</a></li><li><a href=#cogroupbykey>CoGroupByKey</a></li><li><a href=#partition>Partition</a></li><li><a href=#aggregation>Aggregation</a></li><li><a href=#combine>Combine</a></li><li><a href=#side-input>Side Input</a></li><li><a href=#side-output>Side Output</a></li></ul></li><li><a href=#composite-transforms>Composite Transforms</a></li><li><a href=#windowing>Windowing</a><ul><li><a href=#fixed-time-windows>Fixed Time Windows</a></li><li><a href=#sliding-time-windows>Sliding Time Windows</a></li><li><a href=#session-windows>Session Windows</a></li><li><a href=#single-global-window>Single Global Window</a></li><li><a href=#data-freshness-and-system-latency>Data Freshness and System latency</a></li></ul></li><li><a href=#watermarks>Watermarks</a><ul><li><a href=#ideal-window-processing>Ideal Window Processing</a></li><li><a href=#latency-in-data>Latency in data</a></li><li><a href=#adding-timestamps-to-raw-data>Adding timestamps to raw data</a></li></ul></li><li><a href=#triggers>Triggers</a><ul><li><a href=#event-time-triggers>Event Time Triggers</a></li><li><a href=#processing-time-triggers>Processing Time Triggers</a></li><li><a href=#data-driven-triggers>Data Driven Triggers</a></li><li><a href=#composite-triggers>Composite Triggers</a></li></ul></li><li><a href=#sources-and-sinks-io>Sources and Sinks (IO)</a><ul><li><a href=#text-io>Text IO</a></li><li><a href=#bigqueryio>BigQueryIO</a></li><li><a href=#pubsub-io>PubSub IO</a></li><li><a href=#kafka-io>Kafka IO</a></li><li><a href=#bigtable-io>BigTable IO</a></li></ul></li><li><a href=#schema>Schema</a></li><li><a href=#state-and-timers>State and Timers</a></li><li><a href=#splittable-dofnhttpsbeamapacheorgblogsplittable-do-fn><a href=https://beam.apache.org/blog/splittable-do-fn/>Splittable DoFn</a></a></li></ul><ul><li><a href=#autovalue-generation>AutoValue generation</a></li><li><a href=#using-schema>Using Schema</a></li><li><a href=#dead-lettering>Dead Lettering</a></li><li><a href=#json-data-handling>Json Data Handling</a></li><li><a href=#utilize-dofn-lifecycle>Utilize DoFn LifeCycle</a></li><li><a href=#performance-considerationsoptimizations>Performance Considerations/Optimizations</a></li></ul><ul><li><a href=#components>Components</a></li><li><a href=#dataflow-sqlhttpscloudgooglecomdataflowdocsguidessqldataflow-sql-intro><a href=https://cloud.google.com/dataflow/docs/guides/sql/dataflow-sql-intro>Dataflow SQL</a></a><ul><li><a href=#windowing-1>Windowing</a></li></ul></li><li><a href=#beam-dataframeshttpsbeamapacheorgdocumentationdslsdataframesoverviewtextthe20apache20beam20python20sdkon20the20pandas20dataframe20api><a href="https://beam.apache.org/documentation/dsls/dataframes/overview/#:~:text=The%20Apache%20Beam%20Python%20SDK,on%20the%20Pandas%20DataFrame%20API.">Beam DataFrames</a></a></li></ul><ul><li><a href=#developing-and-testing-pipelineshttpscloudgooglecomarchitecturebuilding-production-ready-data-pipelines-using-dataflow-developing-and-testing><a href=https://cloud.google.com/architecture/building-production-ready-data-pipelines-using-dataflow-developing-and-testing>Developing and Testing Pipelines</a></a><ul><li><a href=#pipeline-options>Pipeline Options</a></li></ul></li><li><a href=#deploying-pipelineshttpscloudgooglecomarchitecturebuilding-production-ready-data-pipelines-using-dataflow-deploying><a href=https://cloud.google.com/architecture/building-production-ready-data-pipelines-using-dataflow-deploying>Deploying Pipelines</a></a></li><li><a href=#dataflow-flex-templateshttpscloudgooglecomdataflowdocsguidestemplatesusing-flex-templates><a href=https://cloud.google.com/dataflow/docs/guides/templates/using-flex-templates>Dataflow Flex Templates</a></a></li><li><a href=#network-and-security>Network and Security</a><ul><li><a href=#data-locality>Data locality</a></li><li><a href=#configure-networking>Configure Networking</a></li><li><a href=#encryption>Encryption</a></li></ul></li><li><a href=#reliability>Reliability</a><ul><li><a href=#handling-failureshttpscloudgooglecomarchitecturebuilding-production-ready-data-pipelines-using-dataflow-deployingpipeline_reliability_best_practices><a href=https://cloud.google.com/architecture/building-production-ready-data-pipelines-using-dataflow-deploying#pipeline_reliability_best_practices>Handling Failures</a></a></li></ul></li><li><a href=#dataflow-shuffle-service-batch>Dataflow Shuffle Service: Batch</a><ul><li><a href=#flexible-resource-scheduling-flexrs>Flexible Resource Scheduling (FlexRS)</a></li></ul></li><li><a href=#dataflow-streaming-service>Dataflow Streaming Service</a></li><li><a href=#monitoring-and-debugging-pipelineshttpscloudgooglecomarchitecturebuilding-production-ready-data-pipelines-using-dataflow-monitoring><a href=https://cloud.google.com/architecture/building-production-ready-data-pipelines-using-dataflow-monitoring>Monitoring and Debugging Pipelines</a></a></li></ul></nav></div></details></div><div class=post-content><p><img loading=lazy src=./beam_logo.png alt=Logo></p><h2 id=for-updates>For Updates<a hidden class=anchor aria-hidden=true href=#for-updates>#</a></h2><ul><li><a href=https://beam.apache.org/blog/>Apache Beam Blog and Release</a></li><li><a href=https://beam.apache.org/documentation/resources/learning-resources>Beam Learning Resources</a></li><li><a href=https://github.com/apache/beam/tree/master/examples>Java Examples</a></li><li><a href=https://github.com/apache/beam/tree/master/learning/katas>Beam Katas Learnings</a></li><li><a href=https://github.com/apache/beam/tree/master/sdks/python/apache_beam/examples>Quick Python Snippets/Examples</a></li></ul><h1 id=apache-beam>Apache Beam<a hidden class=anchor aria-hidden=true href=#apache-beam>#</a></h1><p>Apache Beam = <strong>B</strong>atch + Str<strong>eam</strong></p><h1 id=installing-beam-sdk>Installing Beam SDK<a hidden class=anchor aria-hidden=true href=#installing-beam-sdk>#</a></h1><p>For Release info and blog articles on apache beam follow: <a href=https://beam.apache.org/blog/>https://beam.apache.org/blog/</a></p><p>For Java</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=n>implementation</span><span class=w> </span><span class=s>&#34;org.apache.beam:beam-sdks-java-core:2.31.0&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=cm>/* Apache beam for GCP Dataflow */</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>implementation</span><span class=w> </span><span class=s>&#34;org.apache.beam:beam-runners-google-cloud-dataflow-java:2.31.0&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>implementation</span><span class=w> </span><span class=s>&#34;org.apache.beam:beam-sdks-java-io-google-cloud-platform:2.31.0&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>implementation</span><span class=w> </span><span class=err>&#39;</span><span class=n>org</span><span class=p>.</span><span class=na>apache</span><span class=p>.</span><span class=na>beam</span><span class=p>:</span><span class=n>beam</span><span class=o>-</span><span class=n>sdks</span><span class=o>-</span><span class=n>java</span><span class=o>-</span><span class=n>extensions</span><span class=o>-</span><span class=n>google</span><span class=o>-</span><span class=n>cloud</span><span class=o>-</span><span class=n>platform</span><span class=o>-</span><span class=n>core</span><span class=p>:</span><span class=n>2</span><span class=p>.</span><span class=na>31</span><span class=p>.</span><span class=na>0</span><span class=err>&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=cm>/* Apache beam for Direct Runner */</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>implementation</span><span class=w> </span><span class=s>&#34;org.apache.beam:beam-runners-direct-java:2.31.0&#34;</span><span class=w>
</span></span></span></code></pre></div><p>For Python</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>pip</span> <span class=n>install</span> <span class=s1>&#39;apache-beam[gcp,aws,spark,test,docs]&gt;=2.31.0&#39;</span>
</span></span></code></pre></div><h1 id=designing-pipelines>Designing Pipelines<a hidden class=anchor aria-hidden=true href=#designing-pipelines>#</a></h1><h2 id=what-to-consider>What to consider<a hidden class=anchor aria-hidden=true href=#what-to-consider>#</a></h2><ul><li>Source: Messages, Database, Files, etc.</li><li>Data Schema: The structure of the data (preferably lowest granularity). Data is represented as PCollection.</li><li>Transforms: How to manipulate the data? transform, combine, filter, etc. Transforms on data is called PTransforms.</li><li>Sink: Where to store the data? S3, BigQuery, etc.</li><li>Runner: The execution environment. (<a href=https://beam.apache.org/documentation/runners/capability-matrix/>Look into compatibility matrix</a>)</li></ul><h2 id=beam-model>Beam Model<a hidden class=anchor aria-hidden=true href=#beam-model>#</a></h2><p><img loading=lazy src=./beam-model.png alt="Beam Model"></p><h3 id=pipeline>Pipeline<a hidden class=anchor aria-hidden=true href=#pipeline>#</a></h3><p>A pipeline is a graph of transformations that a user constructs that defines the data processing they want to do.</p><h3 id=pcollection>PCollection<a hidden class=anchor aria-hidden=true href=#pcollection>#</a></h3><p>Data being processed in a pipeline is part of a PCollection. Types of PCollections based on data source are:</p><ul><li><strong>Bounded</strong>: it is finite and you know it, as in batch use cases</li><li><strong>Unbounded</strong>: it may be never end, you don’t know, as in streaming use cases</li></ul><p>Characteristics of PCollection:</p><ul><li><strong>Immutable</strong>: State cannot change after it is constructed.</li><li><strong>Serializable</strong>: State of an object can be serialized and transferred in distributed ecosystem.</li></ul><h3 id=ptransforms>PTransforms<a hidden class=anchor aria-hidden=true href=#ptransforms>#</a></h3><p>The operations executed within a pipeline. These are best thought of as operations on PCollections.</p><h3 id=sdk>SDK<a hidden class=anchor aria-hidden=true href=#sdk>#</a></h3><p>A language-specific library for pipeline authors (we often call them “users” even though we have many kinds of users) to build transforms, construct their pipelines and submit them to a runner</p><h3 id=runner>Runner<a hidden class=anchor aria-hidden=true href=#runner>#</a></h3><p>You are going to write a piece of software called a runner that takes a Beam pipeline and executes it using the capabilities of your data processing engine.</p><p>:exclamation: <strong>Note:</strong> Apache beam supports multiple backend like Dataflow, Spark, Flink, etc. <a href=https://beam.apache.org/documentation/runners/capability-matrix/>Apache Beam feature compatibility matrix</a> :exclamation:</p><h2 id=transforms>Transforms<a hidden class=anchor aria-hidden=true href=#transforms>#</a></h2><p>Transforms are what change your data.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=o>[</span>Final Output PCollection<span class=o>]</span> <span class=o>=</span> <span class=o>[</span>Initial Input PCollection<span class=o>]</span>.apply<span class=o>([</span>First Transform<span class=o>])</span>
</span></span><span class=line><span class=cl>    .apply<span class=o>([</span>Second Transform<span class=o>])</span>
</span></span><span class=line><span class=cl>    .apply<span class=o>([</span>Third Transform<span class=o>])</span><span class=p>;</span>
</span></span></code></pre></div><p><a href=https://beam.apache.org/documentation/transforms/java/overview/>Java Transform Catalog</a>
<a href=https://beam.apache.org/documentation/transforms/python/overview/>Python Transfrom Catalog</a></p><h3 id=pardo>ParDo<a hidden class=anchor aria-hidden=true href=#pardo>#</a></h3><p>ParDo is a Beam transform for generic parallel processing. The ParDo processing paradigm is similar to the “Map” phase of a Map/Shuffle/Reduce-style algorithm.</p><p>ParDo is useful for a variety of common data processing operations, including:</p><ul><li>Filtering a data set.</li><li>Formatting or type-converting each element in a data set.</li><li>Extracting parts of each element in a data set.</li><li>Performing computations on each element in a data set.</li></ul><h4 id=dofn-lifecycle>DoFn Lifecycle<a hidden class=anchor aria-hidden=true href=#dofn-lifecycle>#</a></h4><p><img loading=lazy src=./dofn-lifecycle.png alt="DoFn Lifecycle"></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>DoFn</span><span class=p>(</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>setup</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>pass</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>startBundle</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>pass</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>process</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>element</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>pass</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>finishBundle</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>pass</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>teardown</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>pass</span>
</span></span></code></pre></div><h3 id=branching>Branching<a hidden class=anchor aria-hidden=true href=#branching>#</a></h3><p>Single PCollection output to multiple PCollections.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>numbers</span> <span class=o>=</span> <span class=n>p</span> <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Create</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mult5_results</span> <span class=o>=</span> <span class=n>numbers</span> <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>num</span><span class=p>:</span> <span class=n>num</span> <span class=o>*</span> <span class=mi>5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mult10_results</span> <span class=o>=</span> <span class=n>numbers</span> <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>num</span><span class=p>:</span> <span class=n>num</span> <span class=o>*</span> <span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mult5_results</span> <span class=o>|</span> <span class=s2>&#34;Log multiply 5&#34;</span> <span class=o>&gt;&gt;</span> <span class=n>LogElements</span><span class=p>(</span><span class=n>prefix</span><span class=o>=</span><span class=s2>&#34;Multiplied by 5: &#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>mult10_results</span> <span class=o>|</span> <span class=s2>&#34;Log multiply 10&#34;</span> <span class=o>&gt;&gt;</span> <span class=n>LogElements</span><span class=p>(</span><span class=n>prefix</span><span class=o>=</span><span class=s2>&#34;Multiplied by 10: &#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>Output:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>Multiplied by 10: <span class=m>10</span>
</span></span><span class=line><span class=cl>Multiplied by 5: <span class=m>5</span>
</span></span><span class=line><span class=cl>Multiplied by 10: <span class=m>20</span>
</span></span><span class=line><span class=cl>Multiplied by 5: <span class=m>10</span>
</span></span><span class=line><span class=cl>Multiplied by 10: <span class=m>30</span>
</span></span><span class=line><span class=cl>Multiplied by 5: <span class=m>15</span>
</span></span><span class=line><span class=cl>Multiplied by 10: <span class=m>40</span>
</span></span><span class=line><span class=cl>Multiplied by 5: <span class=m>20</span>
</span></span><span class=line><span class=cl>Multiplied by 10: <span class=m>50</span>
</span></span><span class=line><span class=cl>Multiplied by 5: <span class=m>25</span>
</span></span></code></pre></div><h3 id=groupbykey>GroupByKey<a hidden class=anchor aria-hidden=true href=#groupbykey>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>        <span class=n>p</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Create</span><span class=p>([</span><span class=s2>&#34;apple&#34;</span><span class=p>,</span> <span class=s2>&#34;ball&#34;</span><span class=p>,</span> <span class=s2>&#34;car&#34;</span><span class=p>,</span> <span class=s2>&#34;bear&#34;</span><span class=p>,</span> <span class=s2>&#34;cheetah&#34;</span><span class=p>,</span> <span class=s2>&#34;ant&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>word</span><span class=p>:</span> <span class=p>(</span><span class=n>word</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>word</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>GroupByKey</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>LogElements</span><span class=p>()</span>
</span></span></code></pre></div><p>Output:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=o>(</span><span class=s1>&#39;a&#39;</span>, <span class=o>[</span><span class=s1>&#39;apple&#39;</span>, <span class=s1>&#39;ant&#39;</span><span class=o>])</span>
</span></span><span class=line><span class=cl><span class=o>(</span><span class=s1>&#39;b&#39;</span>, <span class=o>[</span><span class=s1>&#39;ball&#39;</span>, <span class=s1>&#39;bear&#39;</span><span class=o>])</span>
</span></span><span class=line><span class=cl><span class=o>(</span><span class=s1>&#39;c&#39;</span>, <span class=o>[</span><span class=s1>&#39;car&#39;</span>, <span class=s1>&#39;cheetah&#39;</span><span class=o>])</span>
</span></span></code></pre></div><h3 id=cogroupbykey>CoGroupByKey<a hidden class=anchor aria-hidden=true href=#cogroupbykey>#</a></h3><p>Group By Key for multiple List of Key Value Pairs.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>apply_transforms</span><span class=p>(</span><span class=n>fruits</span><span class=p>,</span> <span class=n>countries</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>map_to_alphabet_kv</span><span class=p>(</span><span class=n>word</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>(</span><span class=n>word</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>word</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>cogbk_result_to_wordsalphabet</span><span class=p>(</span><span class=n>cgbk_result</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=p>(</span><span class=n>alphabet</span><span class=p>,</span> <span class=n>words</span><span class=p>)</span> <span class=o>=</span> <span class=n>cgbk_result</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>WordsAlphabet</span><span class=p>(</span><span class=n>alphabet</span><span class=p>,</span> <span class=n>words</span><span class=p>[</span><span class=s2>&#34;fruits&#34;</span><span class=p>],</span> <span class=n>words</span><span class=p>[</span><span class=s2>&#34;countries&#34;</span><span class=p>][</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>fruits_kv</span> <span class=o>=</span> <span class=n>fruits</span> <span class=o>|</span> <span class=s2>&#34;Fruit to KV&#34;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=n>map_to_alphabet_kv</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>countries_kv</span> <span class=o>=</span> <span class=n>countries</span> <span class=o>|</span> <span class=s2>&#34;Country to KV&#34;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=n>map_to_alphabet_kv</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s2>&#34;fruits&#34;</span><span class=p>:</span> <span class=n>fruits_kv</span><span class=p>,</span> <span class=s2>&#34;countries&#34;</span><span class=p>:</span> <span class=n>countries_kv</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>CoGroupByKey</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=n>cogbk_result_to_wordsalphabet</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>p</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>fruits</span> <span class=o>=</span> <span class=n>p</span> <span class=o>|</span> <span class=s2>&#34;Fruits&#34;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=p>[</span><span class=s2>&#34;apple&#34;</span><span class=p>,</span> <span class=s2>&#34;banana&#34;</span><span class=p>,</span> <span class=s2>&#34;cherry&#34;</span><span class=p>,</span> <span class=s2>&#34;apricot&#34;</span><span class=p>,</span> <span class=s2>&#34;b-fruit&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>countries</span> <span class=o>=</span> <span class=n>p</span> <span class=o>|</span> <span class=s2>&#34;Countries&#34;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Create</span><span class=p>([</span><span class=s2>&#34;australia&#34;</span><span class=p>,</span> <span class=s2>&#34;brazil&#34;</span><span class=p>,</span> <span class=s2>&#34;canada&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=n>apply_transforms</span><span class=p>(</span><span class=n>fruits</span><span class=p>,</span> <span class=n>countries</span><span class=p>)</span> <span class=o>|</span> <span class=n>LogElements</span><span class=p>())</span>
</span></span></code></pre></div><p>Output:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>WordsAlphabet<span class=o>(</span>alphabet:<span class=s1>&#39;a&#39;</span>, <span class=nv>fruit</span><span class=o>=</span><span class=s1>&#39;[&#39;</span>apple<span class=s1>&#39;, &#39;</span>apricot<span class=s1>&#39;]&#39;</span>, <span class=nv>country</span><span class=o>=</span><span class=s1>&#39;australia&#39;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>WordsAlphabet<span class=o>(</span>alphabet:<span class=s1>&#39;b&#39;</span>, <span class=nv>fruit</span><span class=o>=</span><span class=s1>&#39;[&#39;</span>banana<span class=s1>&#39;, &#39;</span>b-fruit<span class=s1>&#39;]&#39;</span>, <span class=nv>country</span><span class=o>=</span><span class=s1>&#39;brazil&#39;</span><span class=o>)</span>
</span></span><span class=line><span class=cl>WordsAlphabet<span class=o>(</span>alphabet:<span class=s1>&#39;c&#39;</span>, <span class=nv>fruit</span><span class=o>=</span><span class=s1>&#39;[&#39;</span>cherry<span class=s1>&#39;]&#39;</span>, <span class=nv>country</span><span class=o>=</span><span class=s1>&#39;canada&#39;</span><span class=o>)</span>
</span></span></code></pre></div><h3 id=partition>Partition<a hidden class=anchor aria-hidden=true href=#partition>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>partition_fn</span><span class=p>(</span><span class=n>number</span><span class=p>,</span> <span class=n>num_partitions</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>number</span> <span class=o>&gt;</span> <span class=mi>100</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>p</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>p</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Create</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>110</span><span class=p>,</span> <span class=mi>150</span><span class=p>,</span> <span class=mi>250</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Partition</span><span class=p>(</span><span class=n>partition_fn</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>results</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>|</span> <span class=s2>&#34;Log numbers &gt; 100&#34;</span> <span class=o>&gt;&gt;</span> <span class=n>LogElements</span><span class=p>(</span><span class=n>prefix</span><span class=o>=</span><span class=s2>&#34;Number &gt; 100: &#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>|</span> <span class=s2>&#34;Log numbers &lt;= 100&#34;</span> <span class=o>&gt;&gt;</span> <span class=n>LogElements</span><span class=p>(</span><span class=n>prefix</span><span class=o>=</span><span class=s2>&#34;Number &lt;= 100: &#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>Output:</p><pre tabindex=0><code>Number &lt;= 100: 1
Number &lt;= 100: 2
Number &lt;= 100: 3
Number &lt;= 100: 4
Number &lt;= 100: 5
Number &lt;= 100: 100
Number &gt; 100: 110
Number &gt; 100: 150
Number &gt; 100: 250
</code></pre><h3 id=aggregation>Aggregation<a hidden class=anchor aria-hidden=true href=#aggregation>#</a></h3><p>Aggregation - Count</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>p</span> <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Create</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>))</span> <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>combiners</span><span class=o>.</span><span class=n>Count</span><span class=o>.</span><span class=n>Globally</span><span class=p>()</span> <span class=o>|</span> <span class=n>LogElements</span><span class=p>()</span>
</span></span></code></pre></div><p>Output:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=m>10</span>
</span></span></code></pre></div><p>Aggregation - Average</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>p</span> <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Create</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>11</span><span class=p>))</span> <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>combiners</span><span class=o>.</span><span class=n>Mean</span><span class=o>.</span><span class=n>Globally</span><span class=p>()</span> <span class=o>|</span> <span class=n>LogElements</span><span class=p>()</span>
</span></span></code></pre></div><p>Output:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>5.5
</span></span></code></pre></div><h3 id=combine>Combine<a hidden class=anchor aria-hidden=true href=#combine>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>PLAYER_1</span> <span class=o>=</span> <span class=s2>&#34;Player 1&#34;</span>
</span></span><span class=line><span class=cl><span class=n>PLAYER_2</span> <span class=o>=</span> <span class=s2>&#34;Player 2&#34;</span>
</span></span><span class=line><span class=cl><span class=n>PLAYER_3</span> <span class=o>=</span> <span class=s2>&#34;Player 3&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>p</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>p</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span>
</span></span><span class=line><span class=cl>                <span class=p>(</span><span class=n>PLAYER_1</span><span class=p>,</span> <span class=mi>15</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=p>(</span><span class=n>PLAYER_2</span><span class=p>,</span> <span class=mi>10</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=p>(</span><span class=n>PLAYER_1</span><span class=p>,</span> <span class=mi>100</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=p>(</span><span class=n>PLAYER_3</span><span class=p>,</span> <span class=mi>25</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=p>(</span><span class=n>PLAYER_2</span><span class=p>,</span> <span class=mi>75</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>CombinePerKey</span><span class=p>(</span><span class=nb>sum</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>LogElements</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></div><p>Output:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=o>(</span><span class=s1>&#39;Player 1&#39;</span>, 115<span class=o>)</span>
</span></span><span class=line><span class=cl><span class=o>(</span><span class=s1>&#39;Player 2&#39;</span>, 85<span class=o>)</span>
</span></span><span class=line><span class=cl><span class=o>(</span><span class=s1>&#39;Player 3&#39;</span>, 25<span class=o>)</span>
</span></span></code></pre></div><h3 id=side-input>Side Input<a hidden class=anchor aria-hidden=true href=#side-input>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>p</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cities_to_countries</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Beijing&#34;</span><span class=p>:</span> <span class=s2>&#34;China&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;London&#34;</span><span class=p>:</span> <span class=s2>&#34;United Kingdom&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;San Francisco&#34;</span><span class=p>:</span> <span class=s2>&#34;United States&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Singapore&#34;</span><span class=p>:</span> <span class=s2>&#34;Singapore&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;Sydney&#34;</span><span class=p>:</span> <span class=s2>&#34;Australia&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>persons</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=n>Person</span><span class=p>(</span><span class=s2>&#34;Henry&#34;</span><span class=p>,</span> <span class=s2>&#34;Singapore&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>Person</span><span class=p>(</span><span class=s2>&#34;Jane&#34;</span><span class=p>,</span> <span class=s2>&#34;San Francisco&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>Person</span><span class=p>(</span><span class=s2>&#34;Lee&#34;</span><span class=p>,</span> <span class=s2>&#34;Beijing&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>Person</span><span class=p>(</span><span class=s2>&#34;John&#34;</span><span class=p>,</span> <span class=s2>&#34;Sydney&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>Person</span><span class=p>(</span><span class=s2>&#34;Alfred&#34;</span><span class=p>,</span> <span class=s2>&#34;London&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>p</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Create</span><span class=p>(</span><span class=n>persons</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>ParDo</span><span class=p>(</span><span class=n>EnrichCountryDoFn</span><span class=p>(),</span> <span class=n>cities_to_countries</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>LogElements</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></div><p>Output:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>Person<span class=o>[</span>Henry,Singapore,Singapore<span class=o>]</span>
</span></span><span class=line><span class=cl>Person<span class=o>[</span>Jane,San Francisco,United States<span class=o>]</span>
</span></span><span class=line><span class=cl>Person<span class=o>[</span>Lee,Beijing,China<span class=o>]</span>
</span></span><span class=line><span class=cl>Person<span class=o>[</span>John,Sydney,Australia<span class=o>]</span>
</span></span><span class=line><span class=cl>Person<span class=o>[</span>Alfred,London,United Kingdom<span class=o>]</span>
</span></span></code></pre></div><h3 id=side-output>Side Output<a hidden class=anchor aria-hidden=true href=#side-output>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>with beam.Pipeline<span class=o>()</span> as p:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nv>results</span> <span class=o>=</span> <span class=o>(</span>
</span></span><span class=line><span class=cl>        p
</span></span><span class=line><span class=cl>        <span class=p>|</span> beam.Create<span class=o>([</span>10, 50, 120, 20, 200, 0<span class=o>])</span>
</span></span><span class=line><span class=cl>        <span class=p>|</span> beam.ParDo<span class=o>(</span>ProcessNumbersDoFn<span class=o>())</span>.with_outputs<span class=o>(</span>
</span></span><span class=line><span class=cl>            num_above_100_tag, <span class=nv>main</span><span class=o>=</span>num_below_100_tag
</span></span><span class=line><span class=cl>        <span class=o>)</span>
</span></span><span class=line><span class=cl>    <span class=o>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    results<span class=o>[</span>num_below_100_tag<span class=o>]</span> <span class=p>|</span> <span class=s2>&#34;Log numbers &lt;= 100&#34;</span> &gt;&gt; LogElements<span class=o>(</span>
</span></span><span class=line><span class=cl>        <span class=nv>prefix</span><span class=o>=</span><span class=s2>&#34;Number &lt;= 100: &#34;</span>
</span></span><span class=line><span class=cl>    <span class=o>)</span>
</span></span><span class=line><span class=cl>    results<span class=o>[</span>num_above_100_tag<span class=o>]</span> <span class=p>|</span> <span class=s2>&#34;Log numbers &gt; 100&#34;</span> &gt;&gt; LogElements<span class=o>(</span>
</span></span><span class=line><span class=cl>        <span class=nv>prefix</span><span class=o>=</span><span class=s2>&#34;Number &gt; 100: &#34;</span>
</span></span><span class=line><span class=cl>    <span class=o>)</span>
</span></span></code></pre></div><p>Output:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>Number &lt;<span class=o>=</span> 100: <span class=m>10</span>
</span></span><span class=line><span class=cl>Number &lt;<span class=o>=</span> 100: <span class=m>50</span>
</span></span><span class=line><span class=cl>Number &gt; 100: <span class=m>120</span>
</span></span><span class=line><span class=cl>Number &lt;<span class=o>=</span> 100: <span class=m>20</span>
</span></span><span class=line><span class=cl>Number &gt; 100: <span class=m>200</span>
</span></span><span class=line><span class=cl>Number &lt;<span class=o>=</span> 100: <span class=m>0</span>
</span></span></code></pre></div><h2 id=composite-transforms>Composite Transforms<a hidden class=anchor aria-hidden=true href=#composite-transforms>#</a></h2><p>Adding Multiple transforms, Creating your own transforms.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>ExtractAndMultiplyNumbers</span><span class=p>(</span><span class=n>beam</span><span class=o>.</span><span class=n>PTransform</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>expand</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>pcoll</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>pcoll</span>
</span></span><span class=line><span class=cl>            <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>FlatMap</span><span class=p>(</span><span class=k>lambda</span> <span class=n>line</span><span class=p>:</span> <span class=nb>map</span><span class=p>(</span><span class=nb>int</span><span class=p>,</span> <span class=n>line</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;,&#34;</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>            <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>num</span><span class=p>:</span> <span class=n>num</span> <span class=o>*</span> <span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>p</span><span class=p>:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>p</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Create</span><span class=p>([</span><span class=s2>&#34;1,2,3,4,5&#34;</span><span class=p>,</span> <span class=s2>&#34;6,7,8,9,10&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>ExtractAndMultiplyNumbers</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>LogElements</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span></code></pre></div><p>Output:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=m>10</span>
</span></span><span class=line><span class=cl><span class=m>20</span>
</span></span><span class=line><span class=cl><span class=m>30</span>
</span></span><span class=line><span class=cl><span class=m>40</span>
</span></span><span class=line><span class=cl><span class=m>50</span>
</span></span><span class=line><span class=cl><span class=m>60</span>
</span></span><span class=line><span class=cl><span class=m>70</span>
</span></span><span class=line><span class=cl><span class=m>80</span>
</span></span><span class=line><span class=cl><span class=m>90</span>
</span></span><span class=line><span class=cl><span class=m>100</span>
</span></span></code></pre></div><h2 id=windowing>Windowing<a hidden class=anchor aria-hidden=true href=#windowing>#</a></h2><p>Windowing is very useful</p><ul><li>Batch Processing:<ul><li>Handling Chunked data.</li></ul></li><li>Streaming Processing:<ul><li>Dealing with out of order data.</li></ul></li></ul><p>Grouping operations work on windows, for example:</p><ul><li>Bounded data source, can wait till it receives all elements (not memory efficient though)</li><li>GroupByKey, Combine operations from unbounded data is split into windows for processing. (memory efficient)</li></ul><p>Windowing is performed on timestamps.</p><p><img loading=lazy src=./window-by-processing-time.png alt="Window by Processing time"></p><p><img loading=lazy src=./window-by-event-time.png alt="Window by Event time"></p><ul><li>We can assign our own timestamp to each element. i.e. Processing Time</li><li>We can use the event time if already present in the element. i.e. Event Time<ul><li>Late arriving data is placed in correct global windows (In order output)</li></ul></li></ul><blockquote><p>:exclamation: Note: Beam’s default windowing behavior is to assign all elements of a PCollection to a single, global window and discard late data, even for unbounded PCollections. Before you use a grouping transform such as GroupByKey on an unbounded PCollection, you must do at least one of the following:</p><ul><li>Set a non-global windowing function. See Setting your PCollection’s windowing function.</li><li>Set a non-default trigger. This allows the global window to emit results under other conditions, since the default windowing behavior (waiting for all data to arrive) will never occur. :exclamation:</li></ul></blockquote><p><img loading=lazy src=./types-of-windows.png alt="Types of windows"></p><h3 id=fixed-time-windows>Fixed Time Windows<a hidden class=anchor aria-hidden=true href=#fixed-time-windows>#</a></h3><p>Window to divide a PCollection into fixed windows, each 60 seconds in length</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>apache_beam</span> <span class=kn>import</span> <span class=n>window</span>
</span></span><span class=line><span class=cl><span class=n>fixed_windowed_items</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>items</span> <span class=o>|</span> <span class=s1>&#39;window&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>WindowInto</span><span class=p>(</span><span class=n>window</span><span class=o>.</span><span class=n>FixedWindows</span><span class=p>(</span><span class=mi>60</span><span class=p>)))</span>
</span></span></code></pre></div><h3 id=sliding-time-windows>Sliding Time Windows<a hidden class=anchor aria-hidden=true href=#sliding-time-windows>#</a></h3><p>Window to divide a PCollection into sliding time windows. Each window is 30 seconds in length, and a new window begins every five seconds</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>apache_beam</span> <span class=kn>import</span> <span class=n>window</span>
</span></span><span class=line><span class=cl><span class=n>sliding_windowed_items</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>items</span> <span class=o>|</span> <span class=s1>&#39;window&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>WindowInto</span><span class=p>(</span><span class=n>window</span><span class=o>.</span><span class=n>SlidingWindows</span><span class=p>(</span><span class=mi>30</span><span class=p>,</span> <span class=mi>5</span><span class=p>)))</span>
</span></span></code></pre></div><h3 id=session-windows>Session Windows<a hidden class=anchor aria-hidden=true href=#session-windows>#</a></h3><p>Window to divide a PCollection into session windows, where each session must be separated by a time gap of at least 10 minutes (600 seconds), These are <strong>data dependent</strong> windows.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>apache_beam</span> <span class=kn>import</span> <span class=n>window</span>
</span></span><span class=line><span class=cl><span class=n>session_windowed_items</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>items</span> <span class=o>|</span> <span class=s1>&#39;window&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>WindowInto</span><span class=p>(</span><span class=n>window</span><span class=o>.</span><span class=n>Sessions</span><span class=p>(</span><span class=mi>10</span> <span class=o>*</span> <span class=mi>60</span><span class=p>)))</span>
</span></span></code></pre></div><h3 id=single-global-window>Single Global Window<a hidden class=anchor aria-hidden=true href=#single-global-window>#</a></h3><p>If your PCollection is bounded (the size is fixed), you can assign all the elements to a single global window. The following example code shows how to set a single global window for a PCollection</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>apache_beam</span> <span class=kn>import</span> <span class=n>window</span>
</span></span><span class=line><span class=cl><span class=n>global_windowed_items</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>items</span> <span class=o>|</span> <span class=s1>&#39;window&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>WindowInto</span><span class=p>(</span><span class=n>window</span><span class=o>.</span><span class=n>GlobalWindows</span><span class=p>()))</span>
</span></span></code></pre></div><h3 id=data-freshness-and-system-latency>Data Freshness and System latency<a hidden class=anchor aria-hidden=true href=#data-freshness-and-system-latency>#</a></h3><p>Data freshness is the amount of time between the real time and the output watermark (oldest unprocessed element).</p><p><img loading=lazy src=./data-freshness.png alt="Data Freshness - Dataflow"></p><p>System latency is the current maximum duration that an item of data has been processing or awaiting processing.</p><p><img loading=lazy src=./system-latency.png alt="System Latency - Dataflow"></p><h4 id=data-flow-autoscaling-metric>Data flow Autoscaling Metric<a hidden class=anchor aria-hidden=true href=#data-flow-autoscaling-metric>#</a></h4><table><thead><tr><th></th><th>Stable Data freshness</th><th>Ever Increasing data freshness</th></tr></thead><tbody><tr><td>Stable System Latency</td><td>Good Pace (Relax)</td><td>Data Accumulation (High Backlog Autoscale)</td></tr><tr><td>Ever increasing system latency</td><td>Complex Processing, (High CPU Usage Autoscale)</td><td>Complex Processing and Data Accumulation (High Backlog & High CPU Autoscale)</td></tr></tbody></table><h2 id=watermarks>Watermarks<a hidden class=anchor aria-hidden=true href=#watermarks>#</a></h2><p>Watermark is a timestamp that is used to determine the close of a window.</p><p>Window = [Start Time, End Time]
Watermark = [Start Time, End Time + Max Allowed Lag time]</p><p>Just in Time: Within the watermark.
Late Data: Outside the watermark.</p><h3 id=ideal-window-processing>Ideal Window Processing<a hidden class=anchor aria-hidden=true href=#ideal-window-processing>#</a></h3><p><img loading=lazy src=./ideal-windowed-processing.png alt="Ideal Windowed Processing"></p><h3 id=latency-in-data>Latency in data<a hidden class=anchor aria-hidden=true href=#latency-in-data>#</a></h3><p>Latency in data may occur due to various reasons:</p><ul><li>Late arrival - network latency</li><li>Different data processing times.etc&mldr;</li></ul><p><strong>Lag Time</strong>: Its is defined as the difference in time it is expected to arrive and when it actually arrives.</p><p><img loading=lazy src=./latency-in-data.png alt="Latency in Data"></p><h4 id=managing-late-data>Managing Late Data<a hidden class=anchor aria-hidden=true href=#managing-late-data>#</a></h4><p>A windowing strategy that will allow late data up to two days after the end of a window.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=n>pc</span> <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>WindowInto</span><span class=p>(</span>
</span></span><span class=line><span class=cl>              <span class=n>FixedWindows</span><span class=p>(</span><span class=mi>60</span><span class=p>),</span>
</span></span><span class=line><span class=cl>              <span class=n>trigger</span><span class=o>=</span><span class=n>trigger_fn</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>accumulation_mode</span><span class=o>=</span><span class=n>accumulation_mode</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>timestamp_combiner</span><span class=o>=</span><span class=n>timestamp_combiner</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>allowed_lateness</span><span class=o>=</span><span class=n>Duration</span><span class=p>(</span><span class=n>seconds</span><span class=o>=</span><span class=mi>2</span><span class=o>*</span><span class=mi>24</span><span class=o>*</span><span class=mi>60</span><span class=o>*</span><span class=mi>60</span><span class=p>))</span> <span class=c1># 2 days</span>
</span></span></code></pre></div><h3 id=adding-timestamps-to-raw-data>Adding timestamps to raw data<a hidden class=anchor aria-hidden=true href=#adding-timestamps-to-raw-data>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>AddTimestampDoFn</span><span class=p>(</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=nf>process</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>element</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Extract the numeric Unix seconds-since-epoch timestamp to be</span>
</span></span><span class=line><span class=cl>    <span class=c1># associated with the current log entry.</span>
</span></span><span class=line><span class=cl>    <span class=n>unix_timestamp</span> <span class=o>=</span> <span class=n>extract_timestamp_from_log_entry</span><span class=p>(</span><span class=n>element</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># Wrap and emit the current entry and new timestamp in a</span>
</span></span><span class=line><span class=cl>    <span class=c1># TimestampedValue.</span>
</span></span><span class=line><span class=cl>    <span class=k>yield</span> <span class=n>beam</span><span class=o>.</span><span class=n>window</span><span class=o>.</span><span class=n>TimestampedValue</span><span class=p>(</span><span class=n>element</span><span class=p>,</span> <span class=n>unix_timestamp</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>timestamped_items</span> <span class=o>=</span> <span class=n>items</span> <span class=o>|</span> <span class=s1>&#39;timestamp&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>ParDo</span><span class=p>(</span><span class=n>AddTimestampDoFn</span><span class=p>())</span>
</span></span></code></pre></div><h2 id=triggers>Triggers<a hidden class=anchor aria-hidden=true href=#triggers>#</a></h2><p>Triggers determine when to emit aggregated results(pane) from a window.</p><p><img loading=lazy src=./triggers.png alt=Triggers></p><h3 id=event-time-triggers>Event Time Triggers<a hidden class=anchor aria-hidden=true href=#event-time-triggers>#</a></h3><p>Operate on event time.</p><h3 id=processing-time-triggers>Processing Time Triggers<a hidden class=anchor aria-hidden=true href=#processing-time-triggers>#</a></h3><p>Operate on processing time.</p><h3 id=data-driven-triggers>Data Driven Triggers<a hidden class=anchor aria-hidden=true href=#data-driven-triggers>#</a></h3><p>Operates by examining the data arrives and firing when it meets a certain condition.</p><h3 id=composite-triggers>Composite Triggers<a hidden class=anchor aria-hidden=true href=#composite-triggers>#</a></h3><p>Combination of multiple triggers.
Composite trigger that fires whenever the pane has at least 100 elements, or after a minute.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>pcollection</span> <span class=o>|</span> <span class=n>WindowInto</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>FixedWindows</span><span class=p>(</span><span class=mi>1</span> <span class=o>*</span> <span class=mi>60</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>trigger</span><span class=o>=</span><span class=n>Repeatedly</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>AfterAny</span><span class=p>(</span><span class=n>AfterCount</span><span class=p>(</span><span class=mi>100</span><span class=p>),</span> <span class=n>AfterProcessingTime</span><span class=p>(</span><span class=mi>1</span> <span class=o>*</span> <span class=mi>60</span><span class=p>))),</span>
</span></span><span class=line><span class=cl>    <span class=n>accumulation_mode</span><span class=o>=</span><span class=n>AccumulationMode</span><span class=o>.</span><span class=n>DISCARDING</span><span class=p>)</span>
</span></span></code></pre></div><h4 id=window-accumulation-modes>Window Accumulation Modes<a hidden class=anchor aria-hidden=true href=#window-accumulation-modes>#</a></h4><p>Accumulated triggered data and resend or drop already triggered data.</p><h4 id=accumulation-mode>Accumulation Mode<a hidden class=anchor aria-hidden=true href=#accumulation-mode>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>pcollection</span> <span class=o>|</span> <span class=n>WindowInto</span><span class=p>(</span>  <span class=c1># Sliding windows of 1 minute, every 5 seconds</span>
</span></span><span class=line><span class=cl>  <span class=n>SlidingWindows</span><span class=p>(</span><span class=mi>60</span><span class=p>,</span> <span class=mi>5</span><span class=p>),</span>   <span class=c1># Relative to watermark, trigger:</span>
</span></span><span class=line><span class=cl>  <span class=n>trigger</span><span class=o>=</span><span class=n>AfterWatermark</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>early</span><span class=o>=</span><span class=n>AfterProcessingTime</span><span class=p>(</span><span class=n>delay</span><span class=o>=</span><span class=mi>30</span><span class=p>),</span>  <span class=c1># -- fires 30 seconds after pipeline start</span>
</span></span><span class=line><span class=cl>    <span class=n>late</span><span class=o>=</span><span class=n>AfterCount</span><span class=p>(</span><span class=mi>1</span><span class=p>)),</span>  <span class=c1># -- fires when at least one element is late</span>
</span></span><span class=line><span class=cl>  <span class=n>accumulation_mode</span><span class=o>=</span><span class=n>AccumulationMode</span><span class=o>.</span><span class=n>ACCUMULATING</span><span class=p>)</span> <span class=c1># the pane should have all elements</span>
</span></span></code></pre></div><h4 id=discarding-mode>Discarding Mode<a hidden class=anchor aria-hidden=true href=#discarding-mode>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>pcollection</span> <span class=o>|</span> <span class=n>WindowInto</span><span class=p>(</span>  <span class=c1># Fixed windows of 60 seconds</span>
</span></span><span class=line><span class=cl>  <span class=n>FixedWindows</span><span class=p>(</span><span class=mi>60</span><span class=p>),</span>
</span></span><span class=line><span class=cl>  <span class=n>trigger</span><span class=o>=</span><span class=n>Repeatedly</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>AfterAny</span><span class=p>(</span><span class=n>AfterCount</span><span class=p>(</span><span class=mi>100</span><span class=p>),</span> <span class=n>AfterProcessingTime</span><span class=p>(</span><span class=mi>1</span> <span class=o>*</span> <span class=mi>60</span><span class=p>))),</span> <span class=c1># -- fires after 100 elements or 1 minute</span>
</span></span><span class=line><span class=cl>  <span class=n>accumulation_mode</span><span class=o>=</span><span class=n>AccumulationMode</span><span class=o>.</span><span class=n>DISCARDING</span><span class=p>)</span>  <span class=c1># trigger on new records</span>
</span></span><span class=line><span class=cl>  <span class=n>allowed_lateness</span><span class=o>=</span><span class=n>Duration</span><span class=p>(</span><span class=n>seconds</span><span class=o>=</span><span class=mi>2</span><span class=o>*</span><span class=mi>24</span><span class=o>*</span><span class=mi>60</span><span class=o>*</span><span class=mi>60</span><span class=p>))</span> <span class=c1># 2 days</span>
</span></span></code></pre></div><h2 id=sources-and-sinks-io>Sources and Sinks (IO)<a hidden class=anchor aria-hidden=true href=#sources-and-sinks-io>#</a></h2><p>Source: Input data
Sink: Output data</p><p>Bounded Sources (Batch): BigQuery, Cloud Storage, Cloud Spanner</p><ul><li>Split work into smaller chunks, known as bundles.</li><li>Provide estimate of progress.</li><li>Track if units of work can be broken into smaller bundles (<strong>Dynamic work rebalancing</strong>).</li></ul><p>Unbounded Sources (Stream): Pub/Sub</p><ul><li>Checkpointing not to read same data.</li><li>Provide data to service on what point the data is complete using watermarks.</li><li>Deduping data using record/message ID.</li></ul><p><a href=https://beam.apache.org/documentation/io/built-in/>List of Beam IO</a>
<a href=https://github.com/apache/beam/tree/master/website/www/site/content/en/documentation/io>Developing Custom IO</a></p><h3 id=text-io>Text IO<a hidden class=anchor aria-hidden=true href=#text-io>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Read from text</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>p</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>ReadFromText</span><span class=p>(</span><span class=n>file_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>country</span><span class=p>:</span> <span class=n>country</span><span class=o>.</span><span class=n>upper</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        <span class=o>|</span> <span class=n>LogElements</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># File io reading with file names</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>p</span><span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=n>read_pipeline</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>      <span class=n>p</span>
</span></span><span class=line><span class=cl>      <span class=o>|</span> <span class=n>fileio</span><span class=o>.</span><span class=n>MatchFiles</span><span class=p>(</span><span class=n>file_pattern</span><span class=p>)</span> <span class=c1># match file patter like hdfs://path/to/*.txt</span>
</span></span><span class=line><span class=cl>      <span class=o>|</span> <span class=n>fileio</span><span class=o>.</span><span class=n>ReadMatches</span><span class=p>()</span> <span class=c1># read file</span>
</span></span><span class=line><span class=cl>      <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Reshuffle</span><span class=p>()</span> <span class=c1># shuffle data</span>
</span></span><span class=line><span class=cl>  <span class=n>file_and_metadata</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>      <span class=n>read_pipeline</span>
</span></span><span class=line><span class=cl>      <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>metadata</span><span class=o>.</span><span class=n>path</span><span class=p>,</span> <span class=n>x</span><span class=o>.</span><span class=n>read_utf8</span><span class=p>()))</span> <span class=c1># Access file metadata</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># FileIO processing files as they arrive</span>
</span></span><span class=line><span class=cl><span class=n>p</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span>
</span></span><span class=line><span class=cl>  <span class=n>FileIO</span><span class=o>.</span><span class=k>match</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>file_pattern</span><span class=p>(</span><span class=n>file_pattern</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>.</span><span class=n>continuously</span><span class=p>(</span>  <span class=c1># continuously read files</span>
</span></span><span class=line><span class=cl>      <span class=n>Duration</span><span class=o>.</span><span class=n>standardSeconds</span><span class=p>(</span><span class=mi>30</span><span class=p>),</span>
</span></span><span class=line><span class=cl>      <span class=n>Watch</span><span class=o>.</span><span class=n>Growth</span><span class=o>.</span><span class=n>afterTimeSinceNewOutput</span><span class=p>(</span><span class=n>Duration</span><span class=o>.</span><span class=n>standardHours</span><span class=p>(</span><span class=mi>1</span><span class=p>))</span> <span class=c1># Every 30 seconds for 1 hour</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># GCS Buckets have watch functionality to monitor for new files and send a notification to a topic</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>()</span> <span class=k>as</span> <span class=n>p</span><span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=n>read_files</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>p</span>
</span></span><span class=line><span class=cl>    <span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>ReadFromPubSub</span><span class=p>(</span><span class=n>subscription_details</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=o>|</span> <span class=o>&lt;</span><span class=n>decode</span> <span class=n>file</span> <span class=n>name</span><span class=o>&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>files_and_content</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>read_files</span> <span class=o>|</span> <span class=n>ReadAllFromText</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Write to file</span>
</span></span><span class=line><span class=cl><span class=n>csv</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;Write to storage&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=n>TextIO</span><span class=o>.</span><span class=n>write</span><span class=p>()</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>file_path</span><span class=p>)</span><span class=o>.</span><span class=n>withSuffix</span><span class=p>(</span><span class=s2>&#34;.csv&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Writing to dynamic destination</span>
</span></span><span class=line><span class=cl><span class=n>my_pcollection</span>
</span></span><span class=line><span class=cl><span class=o>|</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>fileio</span><span class=o>.</span><span class=n>WriteToFiles</span><span class=p>(</span>
</span></span><span class=line><span class=cl>  <span class=n>path</span><span class=o>=</span><span class=s1>&#39;/my/file/path&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=n>destination</span><span class=o>=</span><span class=k>lambda</span> <span class=n>record</span><span class=p>:</span> <span class=s1>&#39;avro&#39;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>record</span><span class=p>[</span><span class=s1>&#39;type&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=s1>&#39;A&#39;</span> <span class=k>else</span> <span class=s1>&#39;csv&#39;</span>
</span></span><span class=line><span class=cl>  <span class=n>sink</span><span class=o>=</span><span class=k>lambda</span> <span class=n>destination</span><span class=p>,</span> <span class=n>AvroSink</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>destination</span> <span class=o>==</span> <span class=s1>&#39;avro&#39;</span> <span class=k>else</span> <span class=n>CsvSink</span><span class=p>(),</span>  <span class=n>file_naming</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>fileio</span><span class=o>.</span><span class=n>destination_prefix_naming</span><span class=p>())</span>
</span></span></code></pre></div><h3 id=bigqueryio>BigQueryIO<a hidden class=anchor aria-hidden=true href=#bigqueryio>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Read from BigQuery (Using query)</span>
</span></span><span class=line><span class=cl><span class=n>max_temparatures</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>  <span class=n>p</span>
</span></span><span class=line><span class=cl>  <span class=o>|</span> <span class=s1>&#39;QueryTable&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>ReadFromBigQuery</span><span class=p>(</span><span class=n>query</span><span class=o>=</span><span class=s1>&#39;SELECT max_temperature FROM clouddataflow-readonly.samples.weather_stations&#39;</span><span class=p>,</span> <span class=n>use_standard_sql</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span> <span class=c1># Source using big query</span>
</span></span><span class=line><span class=cl>  <span class=o>|</span> <span class=s1>&#39;ExtractMaxTemp&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=k>lambda</span> <span class=n>row</span><span class=p>:</span> <span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=s1>&#39;max_temperature&#39;</span><span class=p>]))</span> <span class=c1># Map results</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=c1>// Read from BigQuery (Using BigQuery Storage API)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>pipeline</span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=s>&#34;Read from BiqQuery table&#34;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>BigQueryIO</span><span class=p>.</span><span class=na>readTableRows</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>.</span><span class=na>from</span><span class=p>(</span><span class=n>String</span><span class=p>.</span><span class=na>format</span><span class=p>(</span><span class=s>&#34;%s:%s.%s&#34;</span><span class=p>,</span><span class=w> </span><span class=n>projectId</span><span class=p>,</span><span class=w> </span><span class=n>datasetId</span><span class=p>,</span><span class=w> </span><span class=n>tableId</span><span class=p>))</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=p>.</span><span class=na>withMethod</span><span class=p>(</span><span class=n>BigQueryIO</span><span class=p>.</span><span class=na>Read</span><span class=p>.</span><span class=na>Method</span><span class=p>.</span><span class=na>DIRECT_READ</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=p>.</span><span class=na>withRowRestriction</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=p>.</span><span class=na>withSelectedFields</span><span class=p>(</span><span class=n>Arrays</span><span class=p>.</span><span class=na>asList</span><span class=p>(</span><span class=s>&#34;max_temperature&#34;</span><span class=p>)))</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=s>&#34;TableRows to MyData&#34;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=n>MapElements</span><span class=p>.</span><span class=na>into</span><span class=p>(</span><span class=n>TypeDescriptors</span><span class=p>.</span><span class=na>of</span><span class=p>(</span><span class=n>MyData</span><span class=p>.</span><span class=na>class</span><span class=p>))</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=p>.</span><span class=na>via</span><span class=p>(</span><span class=n>MyData</span><span class=p>::</span><span class=n>fromTableRow</span><span class=p>));</span><span class=w>
</span></span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># BigQuery IO Write - Dynamic destination</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>table_fn</span><span class=p>(</span><span class=n>element</span><span class=p>,</span> <span class=n>fictional_characters</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=n>element</span> <span class=ow>in</span> <span class=n>fictional_characters</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s1>&#39;my_dataset.fictional_quotes&#39;</span>
</span></span><span class=line><span class=cl>  <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=s1>&#39;my_dataset.real_quotes&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>quotes</span> <span class=o>|</span> <span class=s1>&#39;WriteWithDynamicDestination&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>WriteToBigQuery</span><span class=p>(</span>
</span></span><span class=line><span class=cl>  <span class=n>table_fn</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=n>schema</span><span class=o>=</span><span class=n>table_schema</span><span class=p>,</span> <span class=c1>#&#39;quote:STRING,author:STRING,length:INTEGER&#39;</span>
</span></span><span class=line><span class=cl>  <span class=n>table_side_inputs</span><span class=o>=</span><span class=n>fictional_characters_view</span><span class=p>,)</span>
</span></span></code></pre></div><h3 id=pubsub-io>PubSub IO<a hidden class=anchor aria-hidden=true href=#pubsub-io>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># reading from pubsub topic</span>
</span></span><span class=line><span class=cl><span class=n>p</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=s2>&#34;Read from PubSub&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=n>PubsubIO</span><span class=o>.</span><span class=n>ReadStrings</span><span class=p>()</span><span class=o>.</span><span class=n>from_topic</span><span class=p>(</span><span class=n>topic_name</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=n>WindowInto</span><span class=p>(</span><span class=n>FixedWindows</span><span class=o>.</span><span class=n>of</span><span class=p>(</span><span class=n>Duration</span><span class=o>.</span><span class=n>standardMinutes</span><span class=p>(</span><span class=n>window_size</span><span class=p>))))</span>
</span></span></code></pre></div><h3 id=kafka-io>Kafka IO<a hidden class=anchor aria-hidden=true href=#kafka-io>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=c1>// Read from Kafka topics</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>PCollection</span><span class=o>&lt;</span><span class=n>KV</span><span class=o>&lt;</span><span class=n>String</span><span class=p>,</span><span class=w> </span><span class=n>String</span><span class=o>&gt;&gt;</span><span class=w> </span><span class=n>kafka_messages</span><span class=w> </span><span class=o>=</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>pipeline</span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=s>&#34;Read from Kafka&#34;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>KafkaIO</span><span class=p>.</span><span class=o>&lt;</span><span class=n>String</span><span class=p>,</span><span class=w> </span><span class=n>String</span><span class=o>&gt;</span><span class=n>read</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=p>.</span><span class=na>withConsumerConfigUpdates</span><span class=p>(</span><span class=n>ImmutableMap</span><span class=p>.</span><span class=na>of</span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>ConsumerConfig</span><span class=p>.</span><span class=na>AUTO_OFFSET_RESET_CONFIG</span><span class=p>,</span><span class=w> </span><span class=s>&#34;earliest&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=p>))</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=p>.</span><span class=na>withBootstrapServers</span><span class=p>(</span><span class=n>options</span><span class=p>.</span><span class=na>get</span><span class=p>(</span><span class=s>&#34;bootstrap.servers&#34;</span><span class=p>))</span><span class=w> </span><span class=c1>// &#34;localhost:9092&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=p>.</span><span class=na>withTopics</span><span class=p>(</span><span class=n>list_of_topics</span><span class=p>)</span><span class=w> </span><span class=c1>// &#34;my-topic&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=p>.</span><span class=na>withKeyDeserializerAndCoder</span><span class=p>(</span><span class=n>CustomKeyDeserializer</span><span class=p>.</span><span class=na>class</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=p>.</span><span class=na>withValueDeserializerAndCoder</span><span class=p>(</span><span class=n>CustomValueDeserializer</span><span class=p>.</span><span class=na>class</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=p>.</span><span class=na>withoutMetadata</span><span class=p>());</span><span class=w>
</span></span></span></code></pre></div><blockquote><p>Note: KafkaIO is built in java for python it uses cross language transforms.</p></blockquote><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># read from a kafka topic</span>
</span></span><span class=line><span class=cl><span class=n>pipeline</span> <span class=o>|</span> <span class=s1>&#39;Read from Kafka&#39;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>ReadFromKafka</span><span class=p>(</span>
</span></span><span class=line><span class=cl>  <span class=n>consumer_config</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;bootstrap.servers&#39;</span><span class=p>:</span> <span class=n>bootstrap_servers</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>topics</span><span class=p>:</span> <span class=p>[</span><span class=n>topic</span><span class=p>],</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></div><h3 id=bigtable-io>BigTable IO<a hidden class=anchor aria-hidden=true href=#bigtable-io>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=c1>// Read from big table with row filter</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>PCollection</span><span class=o>&lt;</span><span class=n>BigTableWriteResults</span><span class=o>&gt;</span><span class=w> </span><span class=n>writeResults</span><span class=w> </span><span class=o>=</span><span class=w>  </span><span class=n>p</span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=s>&#34;Read from BigTable&#34;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>BigtableIO</span><span class=p>.</span><span class=na>Read</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>.</span><span class=na>withProjectId</span><span class=p>(</span><span class=n>project_id</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>.</span><span class=na>withInstanceId</span><span class=p>(</span><span class=n>instance_id</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>.</span><span class=na>withTableId</span><span class=p>(</span><span class=n>table_id</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>.</span><span class=na>withRowFilter</span><span class=p>(</span><span class=n>RowFilter</span><span class=p>.</span><span class=na>chain</span><span class=p>()));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Read with column filter and ByteKeyRange is also available.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// BigTable IO Writing with additional actions</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>PCollection</span><span class=o>&lt;</span><span class=n>T</span><span class=o>&gt;</span><span class=w> </span><span class=n>moreData</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=p>...;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>moreData</span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=s>&#34;wait for writes&#34;</span><span class=p>,</span><span class=w> </span><span class=n>Wait</span><span class=p>.</span><span class=na>on</span><span class=p>(</span><span class=n>writeResults</span><span class=p>))</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=s>&#34;Do Something&#34;</span><span class=p>,</span><span class=w> </span><span class=n>ParDo</span><span class=p>.</span><span class=na>of</span><span class=p>(</span><span class=n>customOperation</span><span class=p>()));</span><span class=w>
</span></span></span></code></pre></div><h2 id=schema>Schema<a hidden class=anchor aria-hidden=true href=#schema>#</a></h2><p>A schema describes a type in terms of fields and its values.</p><ul><li>Fields can have string names or numeric indices.</li><li>Field can be one of primitive types (string, int, float, bool, bytes) or a composite type (a list or a map).</li><li>Fields can be optional, repeated, or nullable.</li></ul><p>Schemas can be Avro, ProtoBuf, or JSON.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=c1>// Schemas can be inferred at the sources</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>PCollection</span><span class=o>&lt;</span><span class=n>Purchase</span><span class=o>&gt;</span><span class=w> </span><span class=n>purchase</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>p</span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=n>PubSubIO</span><span class=p>.</span><span class=na>readAvros</span><span class=p>(</span><span class=n>Purchase</span><span class=p>.</span><span class=na>class</span><span class=p>).</span><span class=na>from_topic</span><span class=p>(</span><span class=n>topic_name</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// With Schema filtering purchases in a geographic region</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>purchase</span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>Filter</span><span class=p>.</span><span class=na>whereFieldName</span><span class=p>(</span><span class=s>&#34;location.lat&#34;</span><span class=p>,(</span><span class=kt>double</span><span class=w> </span><span class=n>lat</span><span class=p>)</span><span class=w> </span><span class=o>-&gt;</span><span class=w> </span><span class=n>lat</span><span class=w> </span><span class=o>&gt;</span><span class=w> </span><span class=n>40</span><span class=p>.</span><span class=na>0</span><span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=n>lat</span><span class=w> </span><span class=o>&lt;</span><span class=w> </span><span class=n>45</span><span class=p>.</span><span class=na>0</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>.</span><span class=na>whereFieldName</span><span class=p>(</span><span class=s>&#34;location.lon&#34;</span><span class=p>,(</span><span class=kt>double</span><span class=w> </span><span class=n>lon</span><span class=p>)</span><span class=w> </span><span class=o>-&gt;</span><span class=w> </span><span class=n>lon</span><span class=w> </span><span class=o>&gt;</span><span class=w> </span><span class=o>-</span><span class=n>74</span><span class=p>.</span><span class=na>0</span><span class=w> </span><span class=o>&amp;&amp;</span><span class=w> </span><span class=n>lon</span><span class=w> </span><span class=o>&lt;</span><span class=w> </span><span class=o>-</span><span class=n>70</span><span class=p>.</span><span class=na>0</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Total purchase per transaction</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>PCollection</span><span class=o>&lt;</span><span class=n>UserPurchases</span><span class=o>&gt;</span><span class=w> </span><span class=n>userSums</span><span class=w> </span><span class=o>=</span><span class=w>  </span><span class=n>purchase</span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=n>Join</span><span class=p>.</span><span class=na>innerJoin</span><span class=p>(</span><span class=n>transactions</span><span class=p>).</span><span class=na>using</span><span class=p>(</span><span class=n>transactionId</span><span class=p>))</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=n>Select</span><span class=p>.</span><span class=na>fieldNames</span><span class=p>(</span><span class=s>&#34;lhs.userId&#34;</span><span class=p>,</span><span class=w> </span><span class=s>&#34;rhs.totalPurchase&#34;</span><span class=p>))</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=n>Group</span><span class=p>.</span><span class=na>ByField</span><span class=p>(</span><span class=s>&#34;userId&#34;</span><span class=p>).</span><span class=na>aggregate</span><span class=p>(</span><span class=n>Sum</span><span class=p>.</span><span class=na>ofLongs</span><span class=p>(),</span><span class=w> </span><span class=s>&#34;totalPurchase&#34;</span><span class=p>));</span><span class=w>
</span></span></span></code></pre></div><h2 id=state-and-timers>State and Timers<a hidden class=anchor aria-hidden=true href=#state-and-timers>#</a></h2><p>Stateful Transformations in ParDo</p><ul><li>The input collection needs to be a PCollection of KV&lt;>.</li><li>Any Stateful computations are stored in a local persistent mutable state, it is partitioned by key and window.</li></ul><p>Types of State Variables:</p><ul><li>Value: Read/Write any value (but always the whole value).</li><li>Bag: Cheap Append no ordering on read.</li><li>Combining: Associative and Commutative compaction.</li><li>Map: Read/Write just keys you specify.</li><li>Set: Membership Checking.</li></ul><p>Timers ensure the state is cleared in regular intervals. Using</p><ul><li>Event time Timers<ul><li>Output based on completeness of data</li><li>Absolute times(at 5 AM)</li><li>Final/Authoritative output</li></ul></li><li>Processing time Timers<ul><li>Timeouts</li><li>Relative Times (every 5 mins)</li><li>Periodic output based on state</li></ul></li></ul><p><img loading=lazy src=../assets/state-and-timers.png alt="Stateful Transformations in ParDo"></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Stateful Buffering</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>StatefulBufferingFn</span><span class=p>(</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=n>MAX_BUFFER_SIZE</span> <span class=o>=</span> <span class=mi>500</span><span class=p>;</span>
</span></span><span class=line><span class=cl>  <span class=n>BUFFER_STATE</span> <span class=o>=</span> <span class=n>BagStateSpec</span><span class=p>(</span><span class=s1>&#39;buffer&#39;</span><span class=p>,</span> <span class=n>EventCoder</span><span class=p>())</span>
</span></span><span class=line><span class=cl>  <span class=n>COUNT_STATE</span> <span class=o>=</span> <span class=n>CombiningValueStateSpec</span><span class=p>(</span><span class=s1>&#39;count&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                        <span class=n>VarIntCoder</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                                        <span class=n>combiners</span><span class=o>.</span><span class=n>SumCombineFn</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=nf>process</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>element</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>buffer_state</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>StateParam</span><span class=p>(</span><span class=n>BUFFER_STATE</span><span class=p>),</span>
</span></span><span class=line><span class=cl>              <span class=n>count_state</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>StateParam</span><span class=p>(</span><span class=n>COUNT_STATE</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>buffer_state</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>element</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>count_state</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>count</span> <span class=o>=</span> <span class=n>count_state</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>count</span> <span class=o>&gt;=</span> <span class=n>MAX_BUFFER_SIZE</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=k>for</span> <span class=n>event</span> <span class=ow>in</span> <span class=n>buffer_state</span><span class=o>.</span><span class=n>read</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=k>yield</span> <span class=n>event</span>
</span></span><span class=line><span class=cl>      <span class=n>count_state</span><span class=o>.</span><span class=n>clear</span><span class=p>()</span>
</span></span><span class=line><span class=cl>      <span class=n>buffer_state</span><span class=o>.</span><span class=n>clear</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Stateful Buffering with Event Time timer</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>StatefulBufferingFn</span><span class=p>(</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=n>EXPIRY_TIMER</span> <span class=o>=</span> <span class=n>TimerSpec</span><span class=p>(</span><span class=s1>&#39;expiry&#39;</span><span class=p>,</span> <span class=n>TimeDomain</span><span class=o>.</span><span class=n>WATERMARK</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=nf>process</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>element</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>w</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>WindowParam</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>buffer_state</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>StateParam</span><span class=p>(</span><span class=n>BUFFER_STATE</span><span class=p>),</span>
</span></span><span class=line><span class=cl>              <span class=n>count_state</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>StateParam</span><span class=p>(</span><span class=n>COUNT_STATE</span><span class=p>),</span>
</span></span><span class=line><span class=cl>              <span class=n>expiry_timer</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>TimerParam</span><span class=p>(</span><span class=n>EXPIRY_TIMER</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>expiry_timer</span><span class=o>.</span><span class=n>set</span><span class=p>(</span><span class=n>w</span><span class=o>.</span><span class=n>end</span> <span class=o>+</span> <span class=n>ALLOWED_LATENESS</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=err>…</span> <span class=n>same</span> <span class=n>logic</span> <span class=k>as</span> <span class=n>above</span> <span class=err>…</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nd>@on_timer</span><span class=p>(</span><span class=n>EXPIRY_TIMER</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=nf>expiry</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>             <span class=n>buffer_state</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>StateParam</span><span class=p>(</span><span class=n>BUFFER_STATE</span><span class=p>),</span>
</span></span><span class=line><span class=cl>             <span class=n>count_state</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>StateParam</span><span class=p>(</span><span class=n>COUNT_STATE</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>    <span class=n>events</span> <span class=o>=</span> <span class=n>buffer_state</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>event</span> <span class=ow>in</span> <span class=n>events</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=k>yield</span> <span class=n>event</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>buffer_state</span><span class=o>.</span><span class=n>clear</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>count_state</span><span class=o>.</span><span class=n>clear</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Stateful processing with Processing time timer</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>StatefulBufferingFn</span><span class=p>(</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=n>STALE_TIMER</span> <span class=o>=</span> <span class=n>TimerSpec</span><span class=p>(</span><span class=s1>&#39;stale&#39;</span><span class=p>,</span> <span class=n>TimeDomain</span><span class=o>.</span><span class=n>REAL_TIME</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>MAX_BUFFER_DURATION</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=nf>process</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>element</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>w</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>WindowParam</span><span class=p>,</span>
</span></span><span class=line><span class=cl>              <span class=n>buffer_state</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>StateParam</span><span class=p>(</span><span class=n>BUFFER_STATE</span><span class=p>),</span>
</span></span><span class=line><span class=cl>              <span class=n>count_state</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>StateParam</span><span class=p>(</span><span class=n>COUNT_STATE</span><span class=p>),</span>
</span></span><span class=line><span class=cl>              <span class=n>expiry_timer</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>TimerParam</span><span class=p>(</span><span class=n>EXPIRY_TIMER</span><span class=p>),</span>
</span></span><span class=line><span class=cl>              <span class=n>stale_timer</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>TimerParam</span><span class=p>(</span><span class=n>STALE_TIMER</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>count_state</span><span class=o>.</span><span class=n>read</span><span class=p>()</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>stale_timer</span><span class=o>.</span><span class=n>set</span><span class=p>(</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>+</span> <span class=n>StatefulBufferingFn</span><span class=o>.</span><span class=n>MAX_BUFFER_DURATION</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=err>…</span> <span class=n>same</span> <span class=n>logic</span> <span class=k>as</span> <span class=n>above</span> <span class=err>…</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nd>@on_timer</span><span class=p>(</span><span class=n>STALE_TIMER</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=nf>stale</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>buffer_state</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>StateParam</span><span class=p>(</span><span class=n>BUFFER_STATE</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>count_state</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>StateParam</span><span class=p>(</span><span class=n>COUNT_STATE</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>    <span class=n>events</span> <span class=o>=</span> <span class=n>buffer_state</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>event</span> <span class=ow>in</span> <span class=n>events</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=k>yield</span> <span class=n>event</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>buffer_state</span><span class=o>.</span><span class=n>clear</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>count_state</span><span class=o>.</span><span class=n>clear</span><span class=p>()</span>
</span></span></code></pre></div><p>Use Cases:</p><ul><li>Domain Specific triggering (&ldquo;output when five people who live in Seattle have check in&rdquo;)</li><li>Slowly Changing Dimensions(&ldquo;Update FX rates for a currency&rdquo;)</li><li>Streaming Joins</li><li>Fine Grained Aggregations</li><li>Per key workflows</li></ul><p><a href=https://beam.apache.org/blog/timely-processing/>Timely Processing</a></p><h2 id=splittable-dofnhttpsbeamapacheorgblogsplittable-do-fn><a href=https://beam.apache.org/blog/splittable-do-fn/>Splittable DoFn</a><a hidden class=anchor aria-hidden=true href=#splittable-dofnhttpsbeamapacheorgblogsplittable-do-fn>#</a></h2><p><img loading=lazy src=../assets/splittable-dofn.png alt="Splittable DoFn"></p><p>With Spilttable DoFn&rsquo;s the processing can be split into bundles based on backlog, this unifies batch and stream processing and doesn&rsquo;t differentiate between bounded and unbounded source.</p><p>The SourceIO is responsible for providing backlog estimate and watermark checkpoints, the runner can use this information to tune its execution and performance.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>FileToWordsRestrictionProvider</span><span class=p>(</span><span class=n>beam</span><span class=o>.</span><span class=n>transforms</span><span class=o>.</span><span class=n>core</span><span class=o>.</span><span class=n>RestrictionProvider</span>
</span></span><span class=line><span class=cl>                                       <span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>initial_restriction</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>file_name</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>return</span> <span class=n>OffsetRange</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>os</span><span class=o>.</span><span class=n>stat</span><span class=p>(</span><span class=n>file_name</span><span class=p>)</span><span class=o>.</span><span class=n>st_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>create_tracker</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>restriction</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>return</span> <span class=n>beam</span><span class=o>.</span><span class=n>io</span><span class=o>.</span><span class=n>restriction_trackers</span><span class=o>.</span><span class=n>OffsetRestrictionTracker</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>split</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>file_name</span><span class=p>,</span> <span class=n>restriction</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=c1># Compute and output 64 MiB size ranges to process in parallel</span>
</span></span><span class=line><span class=cl>      <span class=n>split_size</span> <span class=o>=</span> <span class=mi>64</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>&lt;&lt;</span> <span class=mi>20</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>i</span> <span class=o>=</span> <span class=n>restriction</span><span class=o>.</span><span class=n>start</span>
</span></span><span class=line><span class=cl>      <span class=k>while</span> <span class=n>i</span> <span class=o>&lt;</span> <span class=n>restriction</span><span class=o>.</span><span class=n>end</span> <span class=o>-</span> <span class=n>split_size</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>yield</span> <span class=n>OffsetRange</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>i</span> <span class=o>+</span> <span class=n>split_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>i</span> <span class=o>+=</span> <span class=n>split_size</span>
</span></span><span class=line><span class=cl>      <span class=k>yield</span> <span class=n>OffsetRange</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>restriction</span><span class=o>.</span><span class=n>end</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>class</span> <span class=nc>FileToWordsFn</span><span class=p>(</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>process</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>file_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=c1># Alternatively, we can let FileToWordsFn itself inherit from</span>
</span></span><span class=line><span class=cl>        <span class=c1># RestrictionProvider, implement the required methods and let</span>
</span></span><span class=line><span class=cl>        <span class=c1># tracker=beam.DoFn.RestrictionParam() which will use self as</span>
</span></span><span class=line><span class=cl>        <span class=c1># the provider.</span>
</span></span><span class=line><span class=cl>        <span class=n>tracker</span><span class=o>=</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=o>.</span><span class=n>RestrictionParam</span><span class=p>(</span><span class=n>FileToWordsRestrictionProvider</span><span class=p>())):</span>
</span></span><span class=line><span class=cl>      <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>file_name</span><span class=p>)</span> <span class=k>as</span> <span class=n>file_handle</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>file_handle</span><span class=o>.</span><span class=n>seek</span><span class=p>(</span><span class=n>tracker</span><span class=o>.</span><span class=n>current_restriction</span><span class=o>.</span><span class=n>start</span><span class=p>())</span>
</span></span><span class=line><span class=cl>        <span class=k>while</span> <span class=n>tracker</span><span class=o>.</span><span class=n>try_claim</span><span class=p>(</span><span class=n>file_handle</span><span class=o>.</span><span class=n>tell</span><span class=p>()):</span>
</span></span><span class=line><span class=cl>          <span class=k>yield</span> <span class=n>read_next_record</span><span class=p>(</span><span class=n>file_handle</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># Providing the coder is only necessary if it can not be inferred at</span>
</span></span><span class=line><span class=cl>    <span class=c1># runtime.</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>restriction_coder</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>return</span> <span class=o>...</span>
</span></span></code></pre></div><h1 id=cross-language-transforms>Cross Language Transforms<a hidden class=anchor aria-hidden=true href=#cross-language-transforms>#</a></h1><p>Transforms can be shared among SDKs in different languages.</p><p><img loading=lazy src=../assets/cross-language-transform.png alt="Cross Language Transforms"></p><h1 id=best-practices>Best Practices<a hidden class=anchor aria-hidden=true href=#best-practices>#</a></h1><h2 id=autovalue-generation>AutoValue generation<a hidden class=anchor aria-hidden=true href=#autovalue-generation>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=c1>// use AutoValue Class builder to generate POJO&#39;s when not using beam schemas</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nd>@DefaultSchema</span><span class=p>(</span><span class=n>AutoValueSchema</span><span class=p>.</span><span class=na>class</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nd>@AutoValue</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=kd>public</span><span class=w> </span><span class=kd>abstract</span><span class=w> </span><span class=kd>class</span> <span class=nc>TransactionValue</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>public</span><span class=w> </span><span class=kd>abstract</span><span class=w> </span><span class=n>String</span><span class=w> </span><span class=nf>getBank</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>public</span><span class=w> </span><span class=kd>abstract</span><span class=w> </span><span class=kt>double</span><span class=w> </span><span class=nf>getPurchaseAmount</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><h2 id=using-schema>Using Schema<a hidden class=anchor aria-hidden=true href=#using-schema>#</a></h2><p>Use Schemas to define the schema of the PCollection.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>typing</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Purchase</span><span class=p>(</span><span class=n>typing</span><span class=o>.</span><span class=n>NamedTuple</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=n>user_id</span><span class=p>:</span> <span class=nb>str</span>  <span class=c1># The id of the user who made the purchase.</span>
</span></span><span class=line><span class=cl>  <span class=n>item_id</span><span class=p>:</span> <span class=nb>int</span>  <span class=c1># The identifier of the item that was purchased.</span>
</span></span><span class=line><span class=cl>  <span class=n>shipping_address</span><span class=p>:</span> <span class=n>ShippingAddress</span>  <span class=c1># The shipping address, a nested type.</span>
</span></span><span class=line><span class=cl>  <span class=n>cost_cents</span><span class=p>:</span> <span class=nb>int</span>  <span class=c1># The cost of the item</span>
</span></span><span class=line><span class=cl>  <span class=n>transactions</span><span class=p>:</span> <span class=n>typing</span><span class=o>.</span><span class=n>Sequence</span><span class=p>[</span><span class=n>Transaction</span><span class=p>]</span>  <span class=c1># The transactions that paid for this purchase (a list, since the purchase might be spread out over multiple credit cards).</span>
</span></span></code></pre></div><h2 id=dead-lettering>Dead Lettering<a hidden class=anchor aria-hidden=true href=#dead-lettering>#</a></h2><p>In message queueing the dead letter queue is a service implementation to store messages that meet one or more of the following criteria:</p><ul><li>Message that is sent to a queue that does not exist.</li><li>Queue length limit exceeded.</li><li>Message length limit exceeded.</li><li>Message is rejected by another queue exchange.</li><li>Message reaches a threshold read counter number, because it is not consumed. Sometimes this is called a &ldquo;back out queue&rdquo;.</li><li>The message expires due to per-message TTL (time to live)</li><li>Message is not processed successfully.</li></ul><p>Dead letter queue storing of these messages allows developers to look for common patterns and potential software problems</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=kd>final</span><span class=w> </span><span class=n>TupleTag</span><span class=o>&lt;</span><span class=n>String</span><span class=o>&gt;</span><span class=w> </span><span class=n>deadLetterTag</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=k>new</span><span class=w> </span><span class=n>TupleTag</span><span class=o>&lt;&gt;</span><span class=p>(</span><span class=s>&#34;deadLetter&#34;</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=kd>final</span><span class=w> </span><span class=n>TupleTag</span><span class=o>&lt;</span><span class=n>String</span><span class=o>&gt;</span><span class=w> </span><span class=n>successTag</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=k>new</span><span class=w> </span><span class=n>TupleTag</span><span class=o>&lt;&gt;</span><span class=p>(</span><span class=s>&#34;success&#34;</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>PCollection</span><span class=w> </span><span class=n>input</span><span class=w> </span><span class=o>=</span><span class=cm>/**/</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>PCollectionTuple</span><span class=w> </span><span class=n>output</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>input</span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=n>ParDo</span><span class=p>.</span><span class=na>of</span><span class=p>(</span><span class=k>new</span><span class=w> </span><span class=n>DoFn</span><span class=o>&lt;</span><span class=n>String</span><span class=p>,</span><span class=w> </span><span class=n>String</span><span class=o>&gt;</span><span class=p>()</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nd>@ProcessElement</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>public</span><span class=w> </span><span class=kt>void</span><span class=w> </span><span class=nf>processElement</span><span class=p>(</span><span class=n>ProcessContext</span><span class=w> </span><span class=n>c</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>String</span><span class=w> </span><span class=n>element</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>c</span><span class=p>.</span><span class=na>element</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>try</span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=n>c</span><span class=p>.</span><span class=na>output</span><span class=p>(</span><span class=n>process</span><span class=p>(</span><span class=n>c</span><span class=p>.</span><span class=na>element</span><span class=p>()));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>}</span><span class=w> </span><span class=k>catch</span><span class=w> </span><span class=p>(</span><span class=n>Exception</span><span class=w> </span><span class=n>e</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=n>c</span><span class=p>.</span><span class=na>sideOutput</span><span class=p>(</span><span class=n>deadLetterTag</span><span class=p>,</span><span class=w> </span><span class=n>c</span><span class=p>.</span><span class=na>element</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>})).</span><span class=na>writeOutPutTags</span><span class=p>(</span><span class=n>successTag</span><span class=p>,</span><span class=w> </span><span class=n>TupleTagList</span><span class=p>.</span><span class=na>of</span><span class=p>(</span><span class=n>deadLetterTag</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Write dead letter elements to separate sink (Preferred BigQuery sink)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>output</span><span class=p>.</span><span class=na>get</span><span class=p>(</span><span class=n>deadLetterTag</span><span class=p>).</span><span class=na>apply</span><span class=p>(</span><span class=n>TextIO</span><span class=p>.</span><span class=na>write</span><span class=p>().</span><span class=na>to</span><span class=p>(</span><span class=s>&#34;/tmp/deadLetter&#34;</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Process the successful elements</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>output</span><span class=p>.</span><span class=na>get</span><span class=p>(</span><span class=n>successTag</span><span class=p>).</span><span class=na>apply</span><span class=p>(</span><span class=n>TextIO</span><span class=p>.</span><span class=na>write</span><span class=p>().</span><span class=na>to</span><span class=p>(</span><span class=s>&#34;/tmp/success&#34;</span><span class=p>));</span><span class=w>
</span></span></span></code></pre></div><h2 id=json-data-handling>Json Data Handling<a hidden class=anchor aria-hidden=true href=#json-data-handling>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=c1>// AutoValue Schema for Person</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nd>@DefaultSchema</span><span class=p>(</span><span class=n>AutoValueSchema</span><span class=p>.</span><span class=na>class</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nd>@AutoValue</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=kd>abstract</span><span class=w> </span><span class=kd>static</span><span class=w> </span><span class=kd>class</span> <span class=nc>Person</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>public</span><span class=w> </span><span class=kd>static</span><span class=w> </span><span class=n>Person</span><span class=w> </span><span class=nf>of</span><span class=p>(</span><span class=n>String</span><span class=w> </span><span class=n>name</span><span class=p>,</span><span class=w> </span><span class=n>Integer</span><span class=w> </span><span class=n>height</span><span class=p>,</span><span class=w> </span><span class=n>Boolean</span><span class=w> </span><span class=n>knowsJavascript</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>return</span><span class=w> </span><span class=k>new</span><span class=w> </span><span class=n>AutoValue_ToJsonTest_Person</span><span class=p>(</span><span class=n>name</span><span class=p>,</span><span class=w> </span><span class=n>height</span><span class=p>,</span><span class=w> </span><span class=n>knowsJavascript</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>public</span><span class=w> </span><span class=kd>abstract</span><span class=w> </span><span class=n>String</span><span class=w> </span><span class=nf>getName</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>public</span><span class=w> </span><span class=kd>abstract</span><span class=w> </span><span class=n>Integer</span><span class=w> </span><span class=nf>getHeight</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=kd>public</span><span class=w> </span><span class=kd>abstract</span><span class=w> </span><span class=n>Boolean</span><span class=w> </span><span class=nf>getKnowsJavascript</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Schema for Person</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>Schema</span><span class=w> </span><span class=n>personSchema</span><span class=w> </span><span class=o>=</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=n>Schema</span><span class=p>.</span><span class=na>builder</span><span class=p>()</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=p>.</span><span class=na>addStringField</span><span class=p>(</span><span class=s>&#34;name&#34;</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=p>.</span><span class=na>addInt32Field</span><span class=p>(</span><span class=s>&#34;height&#34;</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=p>.</span><span class=na>addBooleanField</span><span class=p>(</span><span class=s>&#34;knowsJavascript&#34;</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=p>.</span><span class=na>build</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Convert Person to Json</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>PCollection</span><span class=o>&lt;</span><span class=n>Row</span><span class=o>&gt;</span><span class=w> </span><span class=n>personRows</span><span class=w> </span><span class=o>=</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=n>persons</span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=n>ToJson</span><span class=p>.</span><span class=na>of</span><span class=p>()).</span><span class=na>apply</span><span class=p>(</span><span class=n>JsonToRow</span><span class=p>.</span><span class=na>withSchema</span><span class=p>(</span><span class=n>personSchema</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Convert Json to Person</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>PCollection</span><span class=o>&lt;</span><span class=n>Person</span><span class=o>&gt;</span><span class=w> </span><span class=n>persons</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>json</span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>JsonToRow</span><span class=p>.</span><span class=na>withSchema</span><span class=p>(</span><span class=n>personSchema</span><span class=p>)).</span><span class=na>apply</span><span class=p>(</span><span class=n>Convert</span><span class=p>.</span><span class=na>to</span><span class=p>(</span><span class=n>Person</span><span class=p>.</span><span class=na>class</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Use dead letter sink for failed messages</span><span class=w>
</span></span></span></code></pre></div><p><a href=https://github.com/GoogleCloudPlatform/dataflow-sample-applications/blob/master/retail/retail-java-applications/data-engineering-dept/business-logic/src/main/java/com/google/dataflow/sample/retail/businesslogic/core/utils/JSONUtils.java>JsonUtils.java</a></p><h2 id=utilize-dofn-lifecycle>Utilize DoFn LifeCycle<a hidden class=anchor aria-hidden=true href=#utilize-dofn-lifecycle>#</a></h2><p>Use DoFn for micro batching</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>DoFn</span><span class=p>(</span><span class=n>beam</span><span class=o>.</span><span class=n>DoFn</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>setup</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>pass</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>startBundle</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=c1># Start Micro batch operations to external services</span>
</span></span><span class=line><span class=cl>      <span class=k>pass</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>process</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>element</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>pass</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>finishBundle</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=c1># Finish Micro batch operations to external services</span>
</span></span><span class=line><span class=cl>      <span class=k>pass</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>teardown</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=k>pass</span>
</span></span></code></pre></div><h2 id=performance-considerationsoptimizations>Performance Considerations/Optimizations<a hidden class=anchor aria-hidden=true href=#performance-considerationsoptimizations>#</a></h2><ul><li>Move steps that reduce data up the pipeline to reduce data volume, like filtering.</li><li>Apply data transforms serially and let Dataflow optimize the DAG, multiple steps can be fused in a single stage for execution in the same worker node.</li><li>External systems<ul><li>look out for back pressure, ensure system is configured for peak volume</li><li>Enable autoscaling to downscale if workers are underutilized.</li></ul></li><li>Use Efficient Coders, i.e, when only part of the data needs to be deserialized for the pipeline and other information can be masked, use such coder&rsquo;s like AvroCoders and ProtoCoders.</li><li>Use Window + Combine using keys when dealing with large windowed aggregations.</li><li>Use Reshuffling and SideInputs to next steps in dataflow during Fan out operations (One element generates multiple elements), These reshuffling work re-balancing to kick in without any fusion operation which may act as a bottleneck on executing that in a single worker.</li><li>Use less logging, and dead letter patterns for error logging with count. i.e, Request to /api/service failed 10 times, rather than writing the log 10 times.</li><li><a href=https://cloud.google.com/blog/products/gcp/writing-dataflow-pipelines-with-scalability-in-mind>Data Skew</a> in keys may cause high load on few workers, like null key may have 500elements/sec and other keys may be significantly less. Use <strong>enableHotKeyLogging</strong> to detect these keys and try using fan outs and reshuffling.</li><li>Key Space and Parallelism<ul><li>Low Parallelism (Too Few Keys) - Use Window + Key</li><li>High Parallelism (Too Many keys) - use hashing and decrease keys</li></ul></li><li>Don&rsquo;t use compressed text files as a source this clogs source<ul><li>Only one machine can read compressed file.</li><li>Fused stages will need to run on the same worker.</li><li>A single machine will need to push data from the file to all other machines.</li></ul></li><li>Collocation of other services helps in performance (Same region/zone)</li><li>Use Dataflow Shuffle/FlexRs for Batch and Use Streaming Engine for Streaming pipelines.</li></ul><p><a href=https://cloud.google.com/blog/products/data-analytics/guide-to-common-cloud-dataflow-use-case-patterns-part-1>Dataflow Patterns - 1</a>
<a href=https://cloud.google.com/blog/products/data-analytics/guide-to-common-cloud-dataflow-use-case-patterns-part-2>Dataflow Patterns - 2</a>
<a href=https://beam.apache.org/documentation/patterns/overview/>Beam pipeline patterns</a></p><h1 id=beam-sql>Beam SQL<a hidden class=anchor aria-hidden=true href=#beam-sql>#</a></h1><p>Beam SQL allows a Beam user (currently only available in Beam Java and Python) to query bounded and unbounded PCollections with SQL statements.</p><p>Features:</p><ul><li>Works on stream and batch inputs.</li><li>Can be embedded in an existing pipeline using SqlTransform, which can be mixed with PTransforms.</li><li>Supports User defined functions.</li><li>Supports multiple dialects<ul><li>Beam Calcite SQL (OSS SQL dialect Compatibility)</li><li>Google ZetaSQL (BigQuery compatible)</li></ul></li><li>Integrated with Schema.</li><li>Stream aggregation supports windowing.</li></ul><h2 id=components>Components<a hidden class=anchor aria-hidden=true href=#components>#</a></h2><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td>BigQuery UI</td><td>Analytical Queries over historical data</td></tr><tr><td>Dataflow SQL UI</td><td>Analytical Queries over real-time data</td></tr><tr><td>Beam SQL</td><td>Integrating SQL within Beam Pipelines</td></tr></tbody></table><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=c1>// Updating SQL statements in existing Beam SQL pipeline</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>String</span><span class=w> </span><span class=n>sql</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s>&#34;SELECT MY_FUNC(c1), c2 FROM PCOLLECTION&#34;</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>PColl</span><span class=o>&lt;</span><span class=n>Row</span><span class=o>&gt;</span><span class=w> </span><span class=n>result</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>pipeline</span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=n>SqlTransform</span><span class=p>.</span><span class=na>query</span><span class=p>(</span><span class=n>sql</span><span class=p>)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>.</span><span class=na>addUdf</span><span class=p>(</span><span class=n>MY_FUNC</span><span class=p>,</span><span class=w> </span><span class=n>MyFunc</span><span class=p>.</span><span class=na>class</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// Dataflow SQL Template</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>Pipeline</span><span class=w> </span><span class=n>pipeline</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>Pipeline</span><span class=p>.</span><span class=na>create</span><span class=p>();</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>DataCatalogTableProvider</span><span class=w> </span><span class=n>tableProvider</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>DataCatalogTableProvider</span><span class=p>.</span><span class=na>create</span><span class=p>(</span><span class=n>options</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>SqlTransform</span><span class=w> </span><span class=n>sqlTransform</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>p</span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=n>SqlTransform</span><span class=p>.</span><span class=na>query</span><span class=p>(</span><span class=n>options</span><span class=p>.</span><span class=na>getQueryString</span><span class=p>()).</span><span class=na>withDefaultTableProvider</span><span class=p>(</span><span class=n>tableProvider</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>for</span><span class=p>(</span><span class=n>Output</span><span class=w> </span><span class=n>output</span><span class=w> </span><span class=p>:</span><span class=w> </span><span class=n>options</span><span class=p>.</span><span class=na>getOutputs</span><span class=p>())</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=n>sqlTransform</span><span class=p>.</span><span class=na>apply</span><span class=p>(</span><span class=n>createSink</span><span class=p>(</span><span class=n>output</span><span class=p>,</span><span class=w> </span><span class=n>tableProvider</span><span class=p>));</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>pipeline</span><span class=p>.</span><span class=na>run</span><span class=p>();</span><span class=w>
</span></span></span></code></pre></div><h2 id=dataflow-sqlhttpscloudgooglecomdataflowdocsguidessqldataflow-sql-intro><a href=https://cloud.google.com/dataflow/docs/guides/sql/dataflow-sql-intro>Dataflow SQL</a><a hidden class=anchor aria-hidden=true href=#dataflow-sqlhttpscloudgooglecomdataflowdocsguidessqldataflow-sql-intro>#</a></h2><p>Features:</p><ul><li>Beam ZetaSQL SqlTransform in Dataflow flex template</li><li>Acts as an optional engine for long running batch jobs.</li></ul><p>Syntax:</p><pre tabindex=0><code># We can specify other dataflow pipeline options also
gcloud dataflow sql query \
  --job-name=JOB_NAME \
  --region=REGION \
  --bigquery-table=BIGQUERY_TABLE \
  --bigquery-dataset=BIGQUERY_DATASET \
  --bigquery-project=BIGQUERY_PROJECT \
  --parameter=NAME:TYPE:VALUE \
&#39;SQL_QUERY&#39;
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=c1># Sample Queries with parameters</span>
</span></span><span class=line><span class=cl>gcloud dataflow sql query <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --job-name<span class=o>=</span>job-name <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --region<span class=o>=</span>region <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --bigquery-dataset<span class=o>=</span>destination-dataset <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --bigquery-table<span class=o>=</span>destination-table <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --parameter<span class=o>=</span>status:STRING:dropoff <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --parameter<span class=o>=</span>price_min:FLOAT64:5.5 <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span><span class=s1>&#39;SELECT *
</span></span></span><span class=line><span class=cl><span class=s1>FROM pubsub.topic.`pubsub-public-data`.`taxirides-realtime`
</span></span></span><span class=line><span class=cl><span class=s1>WHERE
</span></span></span><span class=line><span class=cl><span class=s1>  ride_status = @status
</span></span></span><span class=line><span class=cl><span class=s1>  AND meter_reading &gt;= @price_min&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># With Arrays</span>
</span></span><span class=line><span class=cl>gcloud dataflow sql query <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --job-name<span class=o>=</span>job-name
</span></span><span class=line><span class=cl>  --region<span class=o>=</span>region
</span></span><span class=line><span class=cl>  --bigquery-dataset<span class=o>=</span>destination-dataset <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --bigquery-table<span class=o>=</span>destination-table <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --parameter<span class=o>=</span><span class=s1>&#39;status:ARRAY&lt;STRING&gt;:[&#34;pickup&#34;, &#34;enroute&#34;, &#34;dropoff&#34;]&#39;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span><span class=s1>&#39;SELECT *
</span></span></span><span class=line><span class=cl><span class=s1>FROM pubsub.topic.`pubsub-public-data`.`taxirides-realtime`
</span></span></span><span class=line><span class=cl><span class=s1>WHERE
</span></span></span><span class=line><span class=cl><span class=s1>  ride_status IN UNNEST(@status)&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># With Structs</span>
</span></span><span class=line><span class=cl>gcloud dataflow sql query <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --job-name<span class=o>=</span>job-name <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --region<span class=o>=</span>region <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --bigquery-dataset<span class=o>=</span>destination-dataset <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --bigquery-table<span class=o>=</span>destination-table <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>  --parameter<span class=o>=</span><span class=s1>&#39;date_min:STRING:2020-01-01 00:00:00.000 UTC&#39;</span> <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span><span class=s1>&#39;SELECT *
</span></span></span><span class=line><span class=cl><span class=s1>FROM pubsub.topic.`pubsub-public-data`.`taxirides-realtime`
</span></span></span><span class=line><span class=cl><span class=s1>WHERE
</span></span></span><span class=line><span class=cl><span class=s1>  event_timestamp &gt;= TIMESTAMP (@date_min)&#39;</span>
</span></span></code></pre></div><p><a href=https://beam.apache.org/documentation/dsls/sql/extensions/create-external-table/>Creating external Table</a></p><p><a href=https://cloud.google.com/dataflow/docs/guides/sql/data-sources-destinations>Data Sources and Destinations</a></p><h3 id=windowing-1>Windowing<a hidden class=anchor aria-hidden=true href=#windowing-1>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=c1>-- Fixed Windows
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>SELECT</span><span class=w> </span><span class=n>productid</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>       </span><span class=n>Tumble_start</span><span class=p>(</span><span class=k>timestamp</span><span class=p>,</span><span class=w> </span><span class=nb>INTERVAL</span><span class=w> </span><span class=mi>10</span><span class=w> </span><span class=k>second</span><span class=p>)</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>window_start</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>       </span><span class=k>Count</span><span class=p>(</span><span class=n>transactionid</span><span class=p>)</span><span class=w>                        </span><span class=k>AS</span><span class=w> </span><span class=n>num_purchases</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>FROM</span><span class=w>   </span><span class=n>pubsub</span><span class=p>.</span><span class=n>topic</span><span class=p>.</span><span class=o>`</span><span class=n>instant</span><span class=o>-</span><span class=n>insights</span><span class=o>`</span><span class=p>.</span><span class=o>`</span><span class=n>retaildemo</span><span class=o>-</span><span class=n>online</span><span class=o>-</span><span class=n>purchase</span><span class=o>-</span><span class=n>json</span><span class=o>`</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>pr</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GROUP</span><span class=w>  </span><span class=k>BY</span><span class=w> </span><span class=n>productid</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=n>Tumble</span><span class=p>(</span><span class=k>timestamp</span><span class=p>,</span><span class=w> </span><span class=nb>INTERVAL</span><span class=w> </span><span class=mi>10</span><span class=w> </span><span class=k>second</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- Sliding/Hopping windows
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>SELECT</span><span class=w> </span><span class=n>productid</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>       </span><span class=n>Hop_start</span><span class=p>(</span><span class=k>timestamp</span><span class=p>,</span><span class=w> </span><span class=nb>INTERVAL</span><span class=w> </span><span class=mi>10</span><span class=w> </span><span class=k>second</span><span class=p>,</span><span class=w> </span><span class=nb>INTERVAL</span><span class=w> </span><span class=mi>20</span><span class=w> </span><span class=k>second</span><span class=p>)</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>window_start</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>       </span><span class=n>Hop_end</span><span class=p>(</span><span class=k>timestamp</span><span class=p>,</span><span class=w> </span><span class=nb>INTERVAL</span><span class=w> </span><span class=mi>10</span><span class=w> </span><span class=k>second</span><span class=p>,</span><span class=w> </span><span class=nb>INTERVAL</span><span class=w> </span><span class=mi>20</span><span class=w> </span><span class=k>second</span><span class=p>)</span><span class=w>   </span><span class=k>AS</span><span class=w> </span><span class=n>window_end</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>       </span><span class=k>Count</span><span class=p>(</span><span class=n>transactionid</span><span class=p>)</span><span class=w>                                         </span><span class=k>AS</span><span class=w> </span><span class=n>num_purchases</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>FROM</span><span class=w>   </span><span class=n>pubsub</span><span class=p>.</span><span class=n>topic</span><span class=p>.</span><span class=o>`</span><span class=n>instant</span><span class=o>-</span><span class=n>insights</span><span class=o>`</span><span class=p>.</span><span class=o>`</span><span class=n>retaildemo</span><span class=o>-</span><span class=n>online</span><span class=o>-</span><span class=n>purchase</span><span class=o>-</span><span class=n>json</span><span class=o>`</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>pr</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GROUP</span><span class=w>  </span><span class=k>BY</span><span class=w> </span><span class=n>productid</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=n>Hop</span><span class=p>(</span><span class=k>timestamp</span><span class=p>,</span><span class=w> </span><span class=nb>INTERVAL</span><span class=w> </span><span class=mi>10</span><span class=w> </span><span class=k>second</span><span class=p>,</span><span class=w> </span><span class=nb>INTERVAL</span><span class=w> </span><span class=mi>20</span><span class=w> </span><span class=k>second</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>-- Session Windows
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>SELECT</span><span class=w> </span><span class=n>userid</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>       </span><span class=n>Session_start</span><span class=p>(</span><span class=k>timestamp</span><span class=p>,</span><span class=w> </span><span class=nb>INTERVAL</span><span class=w> </span><span class=mi>10</span><span class=w> </span><span class=k>minute</span><span class=p>)</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>window_start</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>       </span><span class=n>Session_end</span><span class=p>(</span><span class=k>timestamp</span><span class=p>,</span><span class=w> </span><span class=nb>INTERVAL</span><span class=w> </span><span class=mi>10</span><span class=w> </span><span class=k>minute</span><span class=p>)</span><span class=w>   </span><span class=k>AS</span><span class=w> </span><span class=n>window_end</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>       </span><span class=k>Count</span><span class=p>(</span><span class=n>transactionid</span><span class=p>)</span><span class=w>                         </span><span class=k>AS</span><span class=w> </span><span class=n>num_transactions</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>FROM</span><span class=w>   </span><span class=n>pubsub</span><span class=p>.</span><span class=n>topic</span><span class=p>.</span><span class=o>`</span><span class=n>instant</span><span class=o>-</span><span class=n>insights</span><span class=o>`</span><span class=p>.</span><span class=o>`</span><span class=n>retaildemo</span><span class=o>-</span><span class=n>online</span><span class=o>-</span><span class=n>purchase</span><span class=o>-</span><span class=n>json</span><span class=o>`</span><span class=w> </span><span class=k>AS</span><span class=w> </span><span class=n>pr</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>GROUP</span><span class=w>  </span><span class=k>BY</span><span class=w> </span><span class=n>userid</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=k>Session</span><span class=p>(</span><span class=k>timestamp</span><span class=p>,</span><span class=w> </span><span class=nb>INTERVAL</span><span class=w> </span><span class=mi>10</span><span class=w> </span><span class=k>minute</span><span class=p>);</span><span class=w>
</span></span></span></code></pre></div><h2 id=beam-dataframeshttpsbeamapacheorgdocumentationdslsdataframesoverviewtextthe20apache20beam20python20sdkon20the20pandas20dataframe20api><a href="https://beam.apache.org/documentation/dsls/dataframes/overview/#:~:text=The%20Apache%20Beam%20Python%20SDK,on%20the%20Pandas%20DataFrame%20API.">Beam DataFrames</a><a hidden class=anchor aria-hidden=true href=#beam-dataframeshttpsbeamapacheorgdocumentationdslsdataframesoverviewtextthe20apache20beam20python20sdkon20the20pandas20dataframe20api>#</a></h2><h1 id=beam-notebookshttpscloudgooglecomdataflowdocsguidesinteractive-pipeline-development><a href=https://cloud.google.com/dataflow/docs/guides/interactive-pipeline-development>Beam Notebooks</a><a hidden class=anchor aria-hidden=true href=#beam-notebookshttpscloudgooglecomdataflowdocsguidesinteractive-pipeline-development>#</a></h1><h1 id=dataflow>Dataflow<a hidden class=anchor aria-hidden=true href=#dataflow>#</a></h1><p><img loading=lazy src=../assets/dataflow.png alt=Dataflow></p><h2 id=developing-and-testing-pipelineshttpscloudgooglecomarchitecturebuilding-production-ready-data-pipelines-using-dataflow-developing-and-testing><a href=https://cloud.google.com/architecture/building-production-ready-data-pipelines-using-dataflow-developing-and-testing>Developing and Testing Pipelines</a><a hidden class=anchor aria-hidden=true href=#developing-and-testing-pipelineshttpscloudgooglecomarchitecturebuilding-production-ready-data-pipelines-using-dataflow-developing-and-testing>#</a></h2><ul><li>Developing Pipelines</li><li>Testing Pipelines (CI/CD)<ul><li>Unit Testing</li><li>Integration Testing</li><li>End To End Testing</li></ul></li></ul><h3 id=pipeline-options>Pipeline Options<a hidden class=anchor aria-hidden=true href=#pipeline-options>#</a></h3><h2 id=deploying-pipelineshttpscloudgooglecomarchitecturebuilding-production-ready-data-pipelines-using-dataflow-deploying><a href=https://cloud.google.com/architecture/building-production-ready-data-pipelines-using-dataflow-deploying>Deploying Pipelines</a><a hidden class=anchor aria-hidden=true href=#deploying-pipelineshttpscloudgooglecomarchitecturebuilding-production-ready-data-pipelines-using-dataflow-deploying>#</a></h2><ul><li>Dataflow Snapshots</li><li>Updating pipelines</li></ul><h2 id=dataflow-flex-templateshttpscloudgooglecomdataflowdocsguidestemplatesusing-flex-templates><a href=https://cloud.google.com/dataflow/docs/guides/templates/using-flex-templates>Dataflow Flex Templates</a><a hidden class=anchor aria-hidden=true href=#dataflow-flex-templateshttpscloudgooglecomdataflowdocsguidestemplatesusing-flex-templates>#</a></h2><p>Google provides and list of <a href=https://cloud.google.com/dataflow/docs/guides/templates/provided-templates>Steaming, Batch and other utility templates</a>, Flex templates are a way of creating your custom pipeline and building a template using it for reusability.</p><h2 id=network-and-security>Network and Security<a hidden class=anchor aria-hidden=true href=#network-and-security>#</a></h2><h3 id=data-locality>Data locality<a hidden class=anchor aria-hidden=true href=#data-locality>#</a></h3><p>Regional endpoints</p><p>Features:</p><ul><li>Backend that deploys and controls Dataflow workers (Available in only few regions).</li><li>Information flow -> Health Checks, Work Items, Autoscaling, Self healing, Failures, Job Metadata.</li></ul><p>Use cases:</p><ul><li>Security and Compliance needs (Data should not leave the country).</li><li>Minimize network latency and transport costs</li></ul><p>Use Pipeline Options to specify &ndash;region and &ndash;zone endpoints.</p><h3 id=configure-networking>Configure Networking<a hidden class=anchor aria-hidden=true href=#configure-networking>#</a></h3><h4 id=shared-vpc>Shared VPC<a hidden class=anchor aria-hidden=true href=#shared-vpc>#</a></h4><ul><li>Dataflow can use its own network or a subnet from host project.</li><li>Number of VM&rsquo;s is constrained by IP block size. /29 subnet - max workers is 4.</li><li>Dataflow requires Compute Network User role.</li><li>Configurable by using &ndash;network and &ndash;subnet pipeline options(use one).</li></ul><h4 id=ip>IP<a hidden class=anchor aria-hidden=true href=#ip>#</a></h4><ul><li>Use private IP&rsquo;s to secure data processing infrastructure. Block internet access.</li><li>Access control is limited to<ul><li>Same VPC Network</li><li>Other VPC Networks - VPC Peering.</li></ul></li><li>Pipeline options<ul><li>Python: &ndash;no_use_public_ips</li><li>Java: usePublicIps=false.</li></ul></li></ul><h3 id=encryption>Encryption<a hidden class=anchor aria-hidden=true href=#encryption>#</a></h3><p>Understanding datastore associated with Dataflow:</p><ul><li>Persistent Disks</li><li>Storage Buckets</li><li>Dataflow Shuffle Backend - Batch Jobs</li><li>Streaming Engine Backend - Streaming Jobs</li></ul><p>Encryption:</p><ul><li>Google Managed Encryption Key - Job metadata</li><li>Customer Managed Encryption Key - Data keys stored in grouping operations use encryption</li></ul><p>Cloud KMS CryptoKey Encrypter/Decrypter Role is required for Dataflow Service account.</p><p>Pipeline options</p><ul><li>Python: <code>--dataflow_kms_key=projects/$PROJECT/locations/$REGION/keyRings/$KEY_RING/cryptoKeys/$Key</code></li><li>Java: <code>--dataflowKmsKey=projects/$PROJECT/locations/$REGION/keyRings/$KEY_RING/cryptoKeys/$Key</code></li></ul><blockquote><p>Note: Only regional keys are supported, No Global keys.</p></blockquote><h2 id=reliability>Reliability<a hidden class=anchor aria-hidden=true href=#reliability>#</a></h2><p>Batch Pipelines</p><ul><li>Rerun the job if it fails</li><li>Source data is not lost, and partial data written to sinks can be re-written</li></ul><p>Stream Pipelines</p><ul><li>Protection against failure modes<ul><li>User Code Failure<ul><li>Transient Errors</li><li>Data Corruption</li></ul></li><li>Service Failure</li><li>Zonal Failure</li><li>Regional Failure</li></ul></li></ul><h3 id=handling-failureshttpscloudgooglecomarchitecturebuilding-production-ready-data-pipelines-using-dataflow-deployingpipeline_reliability_best_practices><a href=https://cloud.google.com/architecture/building-production-ready-data-pipelines-using-dataflow-deploying#pipeline_reliability_best_practices>Handling Failures</a><a hidden class=anchor aria-hidden=true href=#handling-failureshttpscloudgooglecomarchitecturebuilding-production-ready-data-pipelines-using-dataflow-deployingpipeline_reliability_best_practices>#</a></h3><ul><li>A Batch pipeline get retried up to 4 times, until its marked ad failed.</li><li>A Streaming pipeline can stall indefinitely, Handle Failures using<ul><li>Monitoring pipeline metrics, data freshness, error log count, set up alerting polices.</li><li>Implement Dead Letter Sinks.</li><li>Dataflow is a regional service, avoid specifying zones, as it can avoid zonal outages. (Only on job start, a region or zone is immutable after job start)</li><li>Isolate data processing to one region or use multi regional source (US) and sinks(US) (Data will be synced later if there is any regional outage). Using a source(US-Central) in one region and sink(Us-West) in another have multiple point of failures due to cross regional dependency.</li><li>Use Pubsub Snapshots as a disaster recovery strategy to avoid data loss.<ul><li>Reconciliation of data written in sinks</li><li>Message Reprocessing</li><li>Disrupts exactly once processing</li></ul></li><li>Use Dataflow Snapshots<ul><li>Restart a pipeline without reprocessing in-flight data</li><li>No data loss with minimum downtimes.</li><li>Options to create snapshot with pubsub source.</li></ul></li><li>Snapshots are regional, we should wait for a region to come back online to restart processing.</li><li>Use High availability configurations considering downtime, data loss and cost.</li></ul></li></ul><h2 id=dataflow-shuffle-service-batch>Dataflow Shuffle Service: Batch<a hidden class=anchor aria-hidden=true href=#dataflow-shuffle-service-batch>#</a></h2><p><img loading=lazy src=../assets/dataflow-shuffle.png alt="Dataflow Shuffle"></p><p>Features:</p><ul><li>Faster Execution Time of batch pipeline.</li><li>Reduced consumption on worker&rsquo;s CPU, memory and storage.</li><li>Better autoscaling</li><li>Better Fault tolerance</li></ul><h3 id=flexible-resource-scheduling-flexrs>Flexible Resource Scheduling (FlexRS)<a hidden class=anchor aria-hidden=true href=#flexible-resource-scheduling-flexrs>#</a></h3><p>Features:</p><ul><li>Reduce batch processing costs because of<ul><li>Advanced Scheduling.</li><li>Dataflow Shuffle service.</li><li>Mix of preemptive and Standard VMs.</li></ul></li><li>Execution within 6 hours of job creation</li><li>Suitable for non time-critical workloads.</li><li>Early validation run at job submission.</li></ul><h2 id=dataflow-streaming-service>Dataflow Streaming Service<a hidden class=anchor aria-hidden=true href=#dataflow-streaming-service>#</a></h2><p><img loading=lazy src=../assets/dataflow-streaming.png alt="Dataflow Streaming"></p><p>Features:</p><ul><li>Reduced consumption of worker CPU, memory and storage.</li><li>Lower resource and quota consumption.</li><li>More responsive to autoscaling</li><li>Improved supportability</li></ul><h2 id=monitoring-and-debugging-pipelineshttpscloudgooglecomarchitecturebuilding-production-ready-data-pipelines-using-dataflow-monitoring><a href=https://cloud.google.com/architecture/building-production-ready-data-pipelines-using-dataflow-monitoring>Monitoring and Debugging Pipelines</a><a hidden class=anchor aria-hidden=true href=#monitoring-and-debugging-pipelineshttpscloudgooglecomarchitecturebuilding-production-ready-data-pipelines-using-dataflow-monitoring>#</a></h2><h1 id=further-reading>Further Reading<a hidden class=anchor aria-hidden=true href=#further-reading>#</a></h1><ul><li><a href=https://beam.apache.org/documentation/programming-guide/>Beam Programming Guide</a></li><li><a href=https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/>Streaming 101 World beyond batch</a></li><li><a href=https://www.oreilly.com/radar/the-world-beyond-batch-streaming-102/>Streaming 102 World beyond batch</a></li><li><a href="https://www.youtube.com/watch?v=TWxSLmkWPm4">Understanding Watermarks</a></li><li><a href=https://cloud.google.com/dataflow/docs/how-to>Cloud Dataflow How To</a></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://raghu-vijaykumar.github.io/blog/tags/apache-beam/>Apache Beam</a></li><li><a href=https://raghu-vijaykumar.github.io/blog/tags/dataflow/>Dataflow</a></li><li><a href=https://raghu-vijaykumar.github.io/blog/tags/serverless/>Serverless</a></li></ul><nav class=paginav><a class=next href=https://raghu-vijaykumar.github.io/blog/docs/postgresql/><span class=title>Next »</span><br><span>PostgreSQL</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Apache Beam - Dataflow on x" href="https://x.com/intent/tweet/?text=Apache%20Beam%20-%20Dataflow&amp;url=https%3a%2f%2fraghu-vijaykumar.github.io%2fblog%2fdocs%2fapache-beam%2f&amp;hashtags=apachebeam%2cdataflow%2cserverless"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Apache Beam - Dataflow on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fraghu-vijaykumar.github.io%2fblog%2fdocs%2fapache-beam%2f&amp;title=Apache%20Beam%20-%20Dataflow&amp;summary=Apache%20Beam%20-%20Dataflow&amp;source=https%3a%2f%2fraghu-vijaykumar.github.io%2fblog%2fdocs%2fapache-beam%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Apache Beam - Dataflow on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fraghu-vijaykumar.github.io%2fblog%2fdocs%2fapache-beam%2f&title=Apache%20Beam%20-%20Dataflow"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Apache Beam - Dataflow on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fraghu-vijaykumar.github.io%2fblog%2fdocs%2fapache-beam%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Apache Beam - Dataflow on whatsapp" href="https://api.whatsapp.com/send?text=Apache%20Beam%20-%20Dataflow%20-%20https%3a%2f%2fraghu-vijaykumar.github.io%2fblog%2fdocs%2fapache-beam%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Apache Beam - Dataflow on telegram" href="https://telegram.me/share/url?text=Apache%20Beam%20-%20Dataflow&amp;url=https%3a%2f%2fraghu-vijaykumar.github.io%2fblog%2fdocs%2fapache-beam%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Apache Beam - Dataflow on ycombinator" href="https://news.ycombinator.com/submitlink?t=Apache%20Beam%20-%20Dataflow&u=https%3a%2f%2fraghu-vijaykumar.github.io%2fblog%2fdocs%2fapache-beam%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://raghu-vijaykumar.github.io/blog/>Raghu Vijaykumar</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>